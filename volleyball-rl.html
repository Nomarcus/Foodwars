<!DOCTYPE html>
<html lang="sv">
<head>
    <meta charset="UTF-8">
    <title>AI Volleyball - Reinforcement Learning</title>
    <style>
        body {
            margin: 0;
            background-color: #1a1a1a;
            color: white;
            font-family: monospace;
            display: flex;
            flex-direction: column;
            align-items: center;
            height: 100vh;
            overflow: hidden;
        }
        #gameCanvas {
            background: linear-gradient(to bottom, #2b32b2, #1488cc);
            border: 4px solid #fff;
            box-shadow: 0 0 30px rgba(0,0,0,0.6);
        }
        #ui {
            width: 800px;
            display: flex;
            justify-content: space-between;
            margin-bottom: 10px;
            background: #333;
            padding: 10px;
            border-radius: 8px;
        }
        .stat-box {
            text-align: center;
        }
        button, label {
            cursor: pointer;
            font-size: 14px;
            padding: 5px 10px;
            background: #444;
            border: 1px solid #666;
            color: white;
            border-radius: 4px;
        }
        button:hover { background: #555; }
        input[type="checkbox"] { transform: scale(1.5); margin-right: 5px; }
        .control-panel { display: flex; gap: 20px; align-items: center; }
    </style>
</head>
<body>

    <div id="ui">
        <div class="stat-box" style="color:#FF5722">
            <h3>AI Vänster</h3>
            <div id="scoreP1">Poäng: 0</div>
            <div id="epsilonP1">Utforskning: 100%</div>
        </div>
        
        <div class="control-panel">
            <div class="stat-box">
                <h3>Status</h3>
                <div id="episodeCount">Episod: 0</div>
            </div>
            <label>
                <input type="checkbox" id="fastForward">
                Snabbspola (Träning)
            </label>
            <button onclick="resetAI()">Nollställ Hjärnor</button>
        </div>

        <div class="stat-box" style="color:#4CAF50">
            <h3>AI Höger</h3>
            <div id="scoreP2">Poäng: 0</div>
            <div id="epsilonP2">Utforskning: 100%</div>
        </div>
    </div>

    <canvas id="gameCanvas" width="800" height="450"></canvas>

<script>
/**
 * ENKELT NEURALT NÄTVERK & DEEP Q-LEARNING BIBLIOTEK (Vanilla JS)
 * Författat för att vara snabbt och fungera i webbläsaren utan externa bibliotek.
 */

// Hyperparametrar för inlärning
const LEARNING_RATE = 0.01; // Hur snabbt de anpassar sig
const DISCOUNT_FACTOR = 0.95; // Hur mycket de bryr sig om framtida belöningar
const MEMORY_SIZE = 2000; // Hur många "minnen" de sparar
const BATCH_SIZE = 32; // Hur många minnen de tränar på åt gången

// Aktiveringsfunktioner
const sigmoid = x => 1 / (1 + Math.exp(-x));
const dSigmoid = y => y * (1 - y);
const relu = x => Math.max(0, x);
const dRelu = y => y > 0 ? 1 : 0;

class NeuralNetwork {
    constructor(inputNodes, hiddenNodes, outputNodes) {
        this.inputNodes = inputNodes;
        this.hiddenNodes = hiddenNodes;
        this.outputNodes = outputNodes;

        // Vikter (Slumpmässiga från början)
        this.weightsIH = new Float32Array(this.hiddenNodes * this.inputNodes).map(() => Math.random() * 2 - 1);
        this.weightsHO = new Float32Array(this.outputNodes * this.hiddenNodes).map(() => Math.random() * 2 - 1);
        
        // Bias
        this.biasH = new Float32Array(this.hiddenNodes).map(() => Math.random() * 2 - 1);
        this.biasO = new Float32Array(this.outputNodes).map(() => Math.random() * 2 - 1);
    }

    predict(inputArray) {
        // Input -> Hidden
        let hidden = new Float32Array(this.hiddenNodes);
        for (let i = 0; i < this.hiddenNodes; i++) {
            let sum = 0;
            for (let j = 0; j < this.inputNodes; j++) {
                sum += inputArray[j] * this.weightsIH[i * this.inputNodes + j];
            }
            hidden[i] = relu(sum + this.biasH[i]);
        }

        // Hidden -> Output
        let output = new Float32Array(this.outputNodes);
        for (let i = 0; i < this.outputNodes; i++) {
            let sum = 0;
            for (let j = 0; j < this.hiddenNodes; j++) {
                sum += hidden[i] * this.weightsHO[i * this.hiddenNodes + j];
            }
            output[i] = sum + this.biasO[i]; // Ingen aktivering på sista lagret för Q-värden (Linear)
        }
        return output;
    }

    // Enkel Backpropagation (Stokastisk Gradient Descent)
    train(inputs, targets) {
        // Feedforward (samma som predict men vi sparar hidden states)
        let hidden = new Float32Array(this.hiddenNodes);
        for (let i = 0; i < this.hiddenNodes; i++) {
            let sum = 0;
            for (let j = 0; j < this.inputNodes; j++) {
                sum += inputs[j] * this.weightsIH[i * this.inputNodes + j];
            }
            hidden[i] = relu(sum + this.biasH[i]);
        }

        let outputs = new Float32Array(this.outputNodes);
        for (let i = 0; i < this.outputNodes; i++) {
            let sum = 0;
            for (let j = 0; j < this.hiddenNodes; j++) {
                sum += hidden[j] * this.weightsHO[i * this.hiddenNodes + j];
            }
            outputs[i] = sum + this.biasO[i];
        }

        // Beräkna output errors
        let outputErrors = new Float32Array(this.outputNodes);
        for (let i = 0; i < this.outputNodes; i++) {
            outputErrors[i] = targets[i] - outputs[i];
        }

        // Beräkna hidden gradients
        let hiddenErrors = new Float32Array(this.hiddenNodes);
        for (let i = 0; i < this.hiddenNodes; i++) {
            let sum = 0;
            for (let j = 0; j < this.outputNodes; j++) {
                sum += outputErrors[j] * this.weightsHO[j * this.hiddenNodes + i];
            }
            hiddenErrors[i] = sum;
        }

        // Uppdatera Output Weights
        for (let i = 0; i < this.outputNodes; i++) {
            for (let j = 0; j < this.hiddenNodes; j++) {
                this.weightsHO[i * this.hiddenNodes + j] += LEARNING_RATE * outputErrors[i] * hidden[j];
            }
            this.biasO[i] += LEARNING_RATE * outputErrors[i];
        }

        // Uppdatera Hidden Weights
        for (let i = 0; i < this.hiddenNodes; i++) {
            let gradient = dRelu(hidden[i]) * hiddenErrors[i];
            for (let j = 0; j < this.inputNodes; j++) {
                this.weightsIH[i * this.inputNodes + j] += LEARNING_RATE * gradient * inputs[j];
            }
            this.biasH[i] += LEARNING_RATE * gradient;
        }
    }
}

class Agent {
    constructor(isLeft) {
        this.brain = new NeuralNetwork(6, 16, 3); // Input: 6 (pos, ball), Hidden: 16, Output: 3 (Vänster, Höger, Hopp)
        this.memory = [];
        this.epsilon = 1.0; // Utforskning (100% random i början)
        this.epsilonDecay = 0.9995;
        this.epsilonMin = 0.05;
        this.isLeft = isLeft;
    }

    act(state) {
        // Epsilon-Greedy Strategy
        if (Math.random() < this.epsilon) {
            return Math.floor(Math.random() * 3); // 0, 1, 2
        } else {
            let outputs = this.brain.predict(state);
            // Hitta index för högsta värdet (argmax)
            let maxIndex = 0;
            if (outputs[1] > outputs[0]) maxIndex = 1;
            if (outputs[2] > outputs[maxIndex]) maxIndex = 2;
            return maxIndex;
        }
    }

    remember(state, action, reward, nextState, done) {
        if (this.memory.length > MEMORY_SIZE) this.memory.shift();
        this.memory.push({state, action, reward, nextState, done});
    }

    replay() {
        if (this.memory.length < BATCH_SIZE) return;
        
        // Träna på en slumpmässig batch av minnen
        for (let i = 0; i < BATCH_SIZE; i++) {
            let idx = Math.floor(Math.random() * this.memory.length);
            let mem = this.memory[idx];
            
            let target = mem.reward;
            if (!mem.done) {
                let nextQ = this.brain.predict(mem.nextState);
                let maxNextQ = Math.max(...nextQ);
                target = mem.reward + DISCOUNT_FACTOR * maxNextQ;
            }

            let currentQs = this.brain.predict(mem.state);
            // Vi vill bara ändra Q-värdet för den aktion vi tog, mot target
            let targets = Float32Array.from(currentQs);
            targets[mem.action] = target;

            this.brain.train(mem.state, targets);
        }

        if (this.epsilon > this.epsilonMin) {
            this.epsilon *= this.epsilonDecay;
        }
    }
}

/* --- SPELMOTOR --- */
const canvas = document.getElementById('gameCanvas');
const ctx = canvas.getContext('2d');

const GRAVITY = 0.5;
const JUMP_FORCE = -12;
const SPEED = 5;
const NET_H = 180;
const NET_X = 400;

let episodes = 0;
let p1Score = 0;
let p2Score = 0;

// Fysikobjekt
const p1 = { x: 200, y: 450, vx: 0, vy: 0, r: 40, color: '#FF5722', grounded: false };
const p2 = { x: 600, y: 450, vx: 0, vy: 0, r: 40, color: '#4CAF50', grounded: false };
const ball = { x: 200, y: 200, vx: 0, vy: 0, r: 15 };

// AI Agenter
let agent1 = new Agent(true);
let agent2 = new Agent(false);

// Tillståndshanterare
let currentStateP1, currentStateP2;
let lastActionP1 = 0, lastActionP2 = 0;

function resetBall(winner) {
    ball.x = winner === 1 ? 200 : 600;
    ball.y = 100;
    ball.vx = 0;
    ball.vy = 0;
    p1.x = 200; p1.y = 450; p1.vx = 0; p1.vy = 0;
    p2.x = 600; p2.y = 450; p2.vx = 0; p2.vy = 0;
    episodes++;
    
    // UI Uppdatering
    if (!document.getElementById('fastForward').checked) {
        document.getElementById('episodeCount').innerText = `Episod: ${episodes}`;
        document.getElementById('scoreP1').innerText = `Poäng: ${p1Score}`;
        document.getElementById('scoreP2').innerText = `Poäng: ${p2Score}`;
        document.getElementById('epsilonP1').innerText = `Utforskning: ${(agent1.epsilon*100).toFixed(1)}%`;
        document.getElementById('epsilonP2').innerText = `Utforskning: ${(agent2.epsilon*100).toFixed(1)}%`;
    }
}

function getState(p, opponent, b) {
    // Normalisera värden mellan -1 och 1 för neurala nätverket
    return [
        (p.x - NET_X) / 400, // Relativ position till nät
        (p.y) / 450,
        (p.vx) / 10,
        (p.vy) / 15,
        (b.x - p.x) / 800, // Bollens position relativt mig
        (b.y - p.y) / 450
    ];
}

function updatePhysics() {
    /* --- SPELARE 1 --- */
    currentStateP1 = getState(p1, p2, ball);
    lastActionP1 = agent1.act(currentStateP1);

    // Utför Action (0: Stilla, 1: Vänster, 2: Höger, Hoppa om möjligt)
    if (lastActionP1 === 1) p1.vx = -SPEED;
    else if (lastActionP1 === 2) p1.vx = SPEED;
    else p1.vx = 0;
    
    // Hoppa alltid om AI väljer "Hopp" (action 0 kan vara hoppa också i vissa tolkningar, men låt oss säga att action 0 är "inget/hopp")
    // För enkelhetens skull i RL: 0=Vänster, 1=Höger, 2=Hopp
    // Låt oss mappa om:
    if (lastActionP1 === 0) p1.vx = -SPEED; 
    if (lastActionP1 === 1) p1.vx = SPEED;
    if (lastActionP1 === 2 && p1.grounded) { p1.vy = JUMP_FORCE; p1.grounded = false; }

    /* --- SPELARE 2 --- */
    currentStateP2 = getState(p2, p1, ball);
    lastActionP2 = agent2.act(currentStateP2);
    
    if (lastActionP2 === 0) p2.vx = -SPEED; 
    if (lastActionP2 === 1) p2.vx = SPEED;
    if (lastActionP2 === 2 && p2.grounded) { p2.vy = JUMP_FORCE; p2.grounded = false; }

    // Applicera fysik på spelare
    applyPlayerPhysics(p1);
    applyPlayerPhysics(p2);

    // Begränsa spelare till sin planhalva
    if (p1.x > NET_X - p1.r) p1.x = NET_X - p1.r;
    if (p1.x < p1.r) p1.x = p1.r;
    if (p2.x < NET_X + p2.r) p2.x = NET_X + p2.r;
    if (p2.x > 800 - p2.r) p2.x = 800 - p2.r;

    /* --- BOLLFYSIK --- */
    ball.x += ball.vx;
    ball.y += ball.vy;
    ball.vy += GRAVITY * 0.8;

    // Kollision Spelare-Boll
    let r1 = checkCollision(p1, ball);
    let r2 = checkCollision(p2, ball);

    // Väggstuds
    if (ball.x < ball.r) { ball.x = ball.r; ball.vx *= -0.8; }
    if (ball.x > 800 - ball.r) { ball.x = 800 - ball.r; ball.vx *= -0.8; }
    if (ball.y < ball.r) { ball.y = ball.r; ball.vy *= -0.8; }

    // Nätkollision
    if (ball.x > NET_X - ball.r && ball.x < NET_X + ball.r && ball.y > 450 - NET_H) {
        // Studsa bort
        if (ball.y < 450 - NET_H + 10) {
            ball.vy *= -0.8; ball.y = 450 - NET_H - ball.r; // Toppstuds
        } else {
            ball.vx *= -0.8; // Sidostuds
            if (ball.x < NET_X) ball.x = NET_X - ball.r - 2;
            else ball.x = NET_X + ball.r + 2;
        }
    }

    /* --- BELÖNING & TRÄNING --- */
    // Standardbelöning för att överleva (liten)
    let reward1 = 0.01; 
    let reward2 = 0.01;
    let done = false;

    // Belöning för att nudda boll
    if (r1) reward1 += 0.5;
    if (r2) reward2 += 0.5;

    // Straff för att gå för långt från bollen (Shaping)
    reward1 -= Math.abs(ball.x - p1.x) * 0.0001;
    reward2 -= Math.abs(ball.x - p2.x) * 0.0001;

    // Poäng / Game Over
    if (ball.y + ball.r > 450) {
        done = true;
        if (ball.x < NET_X) {
            // P1 tappade bollen
            reward1 = -1;
            reward2 = 1; // P2 vann
            p2Score++;
            resetBall(1);
        } else {
            // P2 tappade bollen
            reward1 = 1; // P1 vann
            reward2 = -1;
            p1Score++;
            resetBall(2);
        }
    }

    // Träna Agenterna
    let nextStateP1 = getState(p1, p2, ball);
    let nextStateP2 = getState(p2, p1, ball);

    agent1.remember(currentStateP1, lastActionP1, reward1, nextStateP1, done);
    agent2.remember(currentStateP2, lastActionP2, reward2, nextStateP2, done);

    agent1.replay();
    agent2.replay();
}

function applyPlayerPhysics(p) {
    p.vy += GRAVITY;
    p.x += p.vx;
    p.y += p.vy;
    
    // Golv
    if (p.y > 450 - p.r) {
        p.y = 450 - p.r;
        p.vy = 0;
        p.grounded = true;
    }
}

function checkCollision(p, b) {
    let dx = b.x - p.x;
    let dy = b.y - p.y;
    let dist = Math.sqrt(dx*dx + dy*dy);

    if (dist < p.r + b.r) {
        // Vektorlogik för studs
        let angle = Math.atan2(dy, dx);
        let sin = Math.sin(angle);
        let cos = Math.cos(angle);

        // Flytta ut boll
        let overlap = (p.r + b.r) - dist;
        b.x += cos * overlap;
        b.y += sin * overlap;

        // Enkel momentumöverföring (Smash-känsla)
        b.vx = cos * 14 + p.vx * 0.5;
        b.vy = sin * 14 + p.vy * 0.5 - 2; // Extra lyft
        
        // Maxhastighet
        let s = Math.sqrt(b.vx*b.vx + b.vy*b.vy);
        if(s > 18) {
            b.vx = (b.vx/s)*18;
            b.vy = (b.vy/s)*18;
        }
        return true; // Träff
    }
    return false;
}

/* --- RENDERING --- */
function draw() {
    // Rensa
    ctx.fillStyle = '#222';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    // Bakgrund (Himmel/Golv)
    ctx.fillStyle = '#4fc3f7';
    ctx.fillRect(0, 0, 800, 350);
    ctx.fillStyle = '#e0e0e0';
    ctx.fillRect(0, 350, 800, 100);

    // Nät
    ctx.fillStyle = '#fff';
    ctx.fillRect(NET_X - 2, 450 - NET_H, 4, NET_H);

    // Spelare 1
    drawSlime(p1, agent1);
    // Spelare 2
    drawSlime(p2, agent2);

    // Boll
    ctx.beginPath();
    ctx.arc(ball.x, ball.y, ball.r, 0, Math.PI*2);
    ctx.fillStyle = 'white';
    ctx.fill();
    ctx.strokeStyle = 'black';
    ctx.stroke();
}

function drawSlime(p, agent) {
    ctx.beginPath();
    ctx.arc(p.x, p.y, p.r, Math.PI, 0);
    ctx.fillStyle = p.color;
    ctx.fill();
    ctx.stroke();
    
    // Ögon
    let eyeOff = p === p1 ? 12 : -12;
    ctx.fillStyle = 'white';
    ctx.beginPath();
    ctx.arc(p.x + eyeOff, p.y - 20, 10, 0, Math.PI*2);
    ctx.fill();
    
    // Pupill (Tittar på bollen)
    let dx = ball.x - (p.x + eyeOff);
    let dy = ball.y - (p.y - 20);
    let angle = Math.atan2(dy, dx);
    ctx.fillStyle = 'black';
    ctx.beginPath();
    ctx.arc(p.x + eyeOff + Math.cos(angle)*4, p.y - 20 + Math.sin(angle)*4, 4, 0, Math.PI*2);
    ctx.fill();

    // Visa "Tanke" (Linje till bollen om de ser den)
    ctx.strokeStyle = 'rgba(255,255,255,0.2)';
    ctx.beginPath();
    ctx.moveTo(p.x, p.y - 20);
    ctx.lineTo(ball.x, ball.y);
    ctx.stroke();
}

// Huvudloop
function loop() {
    const fastForward = document.getElementById('fastForward').checked;
    
    // Om snabbspolning är på, kör vi fysikloopen många gånger per frame
    const loops = fastForward ? 100 : 1;

    for(let i=0; i<loops; i++) {
        updatePhysics();
    }

    if (!fastForward) {
        draw();
    }

    requestAnimationFrame(loop);
}

function resetAI() {
    agent1 = new Agent(true);
    agent2 = new Agent(false);
    episodes = 0;
    p1Score = 0;
    p2Score = 0;
    resetBall();
}

// Starta
resetBall();
loop();

</script>
</body>
</html>
