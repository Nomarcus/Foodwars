<!DOCTYPE html>
<html lang="sv">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Hybrid Policy Learning (HPL) Data Sorting Simulation - RL-ACO</title>
  <style>
    :root {
      --bg-dark: #050516;
      --panel-bg: rgba(14, 19, 48, 0.9);
      --accent: #38bdf8;
      --accent-ok: #7cf29d;
      --accent-bad: #f472b6;
      --text-main: #f5f7ff;
      --text-dim: #a0accf;
      --font-mono: 'Fira Code', Consolas, monospace;
      --font-ui: 'Inter', system-ui, sans-serif;
    }
    * { box-sizing: border-box; user-select: none; }
    body {
      margin: 0; overflow: hidden; background: radial-gradient(circle at 18% 10%, rgba(56,189,248,.18) 0%, transparent 46%), radial-gradient(circle at 82% 8%, rgba(244,114,182,.16) 0%, transparent 54%), radial-gradient(circle at 12% 78%, rgba(124,242,157,.12) 0%, transparent 55%), linear-gradient(160deg, var(--bg-dark) 0%, #0f1536 55%, #1a2344 100%); color: var(--text-main);
      font-family: var(--font-ui); display: flex; height: 100vh;
    }
    
    /* Layout */
    .sidebar {
      width: 360px; flex-shrink: 0; display: flex; flex-direction: column;
      background: linear-gradient(180deg, rgba(14, 19, 48, 0.95) 0%, rgba(10,14,35,0.9) 50%, rgba(12,17,40,0.85) 100%);
      border-right: 1px solid rgba(148,163,209,.28);
      box-shadow: 0 10px 40px rgba(0,0,0,0.35);
      backdrop-filter: blur(10px); z-index: 10; overflow-y: auto;
    }
    .main-view { 
        flex: 1; 
        position: relative; 
    }
    
    /* Viewport with improved background gradient */
    .viewport {
        width: 100%;
        height: 100%;
        position: relative;
        background: radial-gradient(circle at 50% 30%, #0b1525 0%, #04070f 80%);
        overflow: hidden;
    }
    .viewport::before {
        content: "";
        position: absolute;
        inset: 0;
        background: radial-gradient(circle at 20% 20%, rgba(56,189,248,0.1), transparent 35%),
                    radial-gradient(circle at 80% 10%, rgba(244,114,182,0.12), transparent 45%),
                    radial-gradient(circle at 50% 80%, rgba(124,242,157,0.12), transparent 40%),
                    linear-gradient(120deg, rgba(255,255,255,0.04) 0%, rgba(255,255,255,0) 20%, rgba(255,255,255,0.04) 40%, rgba(255,255,255,0) 60%, rgba(255,255,255,0.04) 80%);
        pointer-events: none;
        mix-blend-mode: screen;
    }
    .viewport::after {
        content: "";
        position: absolute;
        inset: 0;
        background-image: linear-gradient(rgba(255,255,255,0.04) 1px, transparent 1px),
                          linear-gradient(90deg, rgba(255,255,255,0.04) 1px, transparent 1px);
        background-size: 120px 120px;
        opacity: 0.18;
        pointer-events: none;
    }
    canvas#simCanvas { display: block; width: 100%; height: 100%; cursor: crosshair; }
    
    /* UI Elements */
    .panel-section { padding: 15px; border-bottom: 1px solid rgba(148,163,209,.28); }
    h1 { font-size: 18px; margin: 0 0 10px; color: var(--accent); text-transform: uppercase; letter-spacing: 1px; text-align: center; }
    h2 { font-size: 12px; margin: 15px 0 8px; color: var(--text-dim); text-transform: uppercase; letter-spacing: 0.5px; border-bottom: 1px solid rgba(148,163,209,.28); padding-bottom: 4px; }
    
    .stat-grid { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 8px; }
    .stat-box { background: rgba(0,0,0,0.3); padding: 8px; border-radius: 6px; border: 1px solid #334; display:flex; flex-direction:column; }
    .stat-label { font-size: 10px; color: var(--text-dim); margin-bottom: 2px; }
    .stat-val { font-size: 15px; font-weight: bold; font-family: var(--font-mono); color: #fff; }
    
    .control-group { margin-bottom: 12px; }
    label { display: flex; justify-content: space-between; font-size: 11px; margin-bottom: 4px; color: var(--text-dim); }
    label span { color: var(--accent); font-family: var(--font-mono); }
    input[type=range] { width: 100%; accent-color: var(--accent); height: 4px; border-radius: 2px; background: #334; cursor: pointer; }
    select {
      width: 100%;
      padding: 6px 8px;
      border-radius: 6px;
      border: 1px solid rgba(148,163,209,.28);
      background: rgba(0,0,0,0.35);
      color: var(--text-main);
      font-size: 11px;
    }
    
    .btn-group { display: flex; gap: 5px; margin-top: 5px; }
    .btn {
      flex: 1; padding: 10px; background: linear-gradient(90deg, rgba(0,234,255,0.1), rgba(0,234,255,0.2));
      border: 1px solid var(--accent); color: var(--accent); font-weight: bold; text-transform: uppercase; font-size: 11px;
      cursor: pointer; transition: all 0.2s; border-radius: 4px; letter-spacing: 1px;
    }
    .btn:hover { background: var(--accent); color: #000; box-shadow: 0 0 15px var(--accent); }
    .btn.danger { border-color: var(--accent-bad); color: var(--accent-bad); background: rgba(255,51,102,0.1); }
    .btn.danger:hover { background: var(--accent-bad); color: #fff; box-shadow: 0 0 15px var(--accent-bad); }
    .btn.alt { border-color: var(--accent-ok); color: var(--accent-ok); background: rgba(0,255,153,0.1); }
    .btn.alt:hover { background: var(--accent-ok); color: #000; box-shadow: 0 0 15px var(--accent-ok); }

    /* Legends & Pulse */
    .legend-grid { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 8px; margin-bottom: 10px; }
    .legend-item { background: rgba(255,255,255,0.03); border:1px solid rgba(148,163,209,.28); border-radius: 8px; padding: 8px; text-align:center; }
    .legend-dot { width: 10px; height: 10px; border-radius: 50%; display:inline-block; margin-right: 4px; box-shadow: 0 0 8px currentColor; }

    .pulse-grid { display:grid; grid-template-columns:1fr; gap:8px; }
    .pulse-row { display:flex; align-items:center; gap:8px; }
    .pulse-label { font-size:11px; color:var(--text-dim); letter-spacing:0.5px; }
    .pulse-bar { flex:1; background: rgba(255,255,255,0.04); border:1px solid rgba(148,163,209,.28); border-radius:12px; height:10px; position:relative; overflow:hidden; }
    .pulse-bar span { position:absolute; inset:0; width:35%; background:linear-gradient(90deg, var(--accent), var(--accent-ok)); box-shadow:0 0 12px rgba(56,189,248,0.8); border-radius:12px; transition:width 0.3s ease; }
    .pulse-value { font-family: var(--font-mono); font-size:11px; color:var(--accent-ok); }
    .smart-list { list-style: none; margin: 0; padding: 0; display: grid; gap: 6px; }
    .smart-list li { font-size: 11px; color: var(--text-dim); padding: 6px 8px; border-radius: 6px; border: 1px solid rgba(148,163,209,.2); background: rgba(255,255,255,0.03); }
    .smart-list li strong { color: var(--accent-ok); }

    .episode-progress { position:absolute; top:38px; left:20px; right:20px; height:8px; border-radius:12px; background:rgba(255,255,255,0.08); overflow:hidden; box-shadow:0 0 12px rgba(0,0,0,0.4); }
    .episode-progress .fill { height:100%; background:linear-gradient(90deg, rgba(56,189,248,0.2), rgba(124,242,157,0.5), rgba(244,114,182,0.35)); width:0%; transition:width 0.2s ease; }

    .mini-callouts { display:grid; grid-template-columns:1fr 1fr; gap:8px; margin-top:10px; }
    .callout { background:linear-gradient(135deg, rgba(56,189,248,0.08), rgba(244,114,182,0.06)); border:1px solid rgba(148,163,209,.28); border-radius:8px; padding:8px; font-size:11px; color:var(--text-dim); }
    .callout strong { color:var(--accent); }

    
    /* HUD Overlay */
    .hud { position: absolute; pointer-events: none; padding: 20px; width: 100%; display: flex; justify-content: space-between; top: 0; }
    .generation-display { font-size: 40px; font-weight: 900; color: rgba(255,255,255,0.1); font-family: var(--font-mono); }
    .live-feed { position: absolute; bottom: 20px; left: 20px; max-width: 300px; display: flex; flex-direction: column-reverse; gap: 5px; pointer-events: none; }
    .feed-item { background: rgba(0,0,0,0.6); padding: 6px 10px; border-radius: 4px; font-size: 11px; border-left: 3px solid var(--text-dim); animation: fadeIn 0.3s ease-out; }
    .feed-item.good { border-color: var(--accent-ok); }
    .feed-item.warn { border-color: #ff9900; }
    .feed-item.bad { border-color: var(--accent-bad); }
    
    @keyframes fadeIn { from { opacity: 0; transform: translateX(-10px); } to { opacity: 1; transform: translateX(0); } }

    /* Brain & Graph */
    #brainCanvas { 
        width: 100%; 
        height: 150px; 
        background: #0a0a12; 
        border: 1px solid #334; 
        border-radius: 6px; 
        margin-top: 5px; 
    }
    #fitnessGraph { width: 100%; height: 70px; background: #0a0a12; border: 1px solid #334; border-radius: 6px; margin-top: 5px; }
    
    .checkbox-row { display: flex; align-items: center; gap: 8px; margin-bottom: 6px; font-size: 12px; cursor: pointer; }
    .checkbox-row input { accent-color: var(--accent); }
    
    /* Agent Hover Tooltip */
    #hoverTip {
        position: absolute; background: rgba(0,0,0,0.85); padding: 8px; border-radius: 4px; border: 1px solid var(--accent);
        font-size: 10px; font-family: var(--font-mono); color: var(--text-main); pointer-events: none; z-index: 1000;
        transform: translate(15px, 15px); transition: opacity 0.1s; opacity: 0;
        line-height: 1.6;
    }

    /* Top Bar for Simulation View */
    .sim-top-bar {
        position: absolute; top: 0; left: 0; width: 100%;
        display: flex; justify-content: space-between; align-items: center;
        padding: 8px 20px; background: rgba(0,0,0,0.2);
        color: var(--text-dim); font-size: 11px;
    }
    .sim-top-bar .fps-counter { font-family: var(--font-mono); color: var(--accent-ok); }

    /* Glow overlays */
    .neon-pulse {
        position:absolute;
        inset:0;
        pointer-events:none;
        background:radial-gradient(circle at 50% 50%, rgba(56,189,248,0.05), transparent 45%),
                  radial-gradient(circle at 15% 70%, rgba(124,242,157,0.06), transparent 35%),
                  radial-gradient(circle at 80% 20%, rgba(244,114,182,0.05), transparent 40%);
        mix-blend-mode:screen;
        animation: pulse 6s ease-in-out infinite;
    }
    @keyframes pulse {
        0%,100%{opacity:0.4;}50%{opacity:0.8;}
    }
  </style>
</head>
<body>

<aside class="sidebar">
  <div class="panel-section">
    <h1>HPL Control Console</h1>
    
    <div class="stat-grid">
      <div class="stat-box">
        <span class="stat-label">Episode</span>
        <span class="stat-val" id="dispGen">1</span>
      </div>
      <div class="stat-box">
        <span class="stat-label">Best Q-Score</span>
        <span class="stat-val" id="dispFit" style="color:var(--accent-ok)">0.0</span>
      </div>
      <div class="stat-box">
        <span class="stat-label">Accuracy</span>
        <span class="stat-val" id="dispAcc">0%</span>
      </div>
      <div class="stat-box">
        <span class="stat-label">Successes</span>
        <span class="stat-val" id="dispSolved" style="color:var(--accent-ok)">0</span>
      </div>
      <div class="stat-box">
        <span class="stat-label">Mistakes</span>
        <span class="stat-val" id="dispWrong" style="color:var(--accent-bad)">0</span>
      </div>
      <div class="stat-box">
        <span class="stat-label">Active Agents</span>
        <span class="stat-val" id="dispActive">40/40</span>
      </div>
    </div>
  </div>
  
  <div class="panel-section">
    <h2>Performance History (Best Agent)</h2>
    <canvas id="fitnessGraph"></canvas>
  </div>

  <div class="panel-section">
    <h2>Signal Legend</h2>
    <div class="legend-grid">
      <div class="legend-item"><span class="legend-dot" style="color:#ff3366"></span>Incident</div>
      <div class="legend-item"><span class="legend-dot" style="color:#00ff99"></span>Service</div>
      <div class="legend-item"><span class="legend-dot" style="color:#00eaff"></span>Problem</div>
    </div>
    <div class="mini-callouts">
      <div class="callout"><strong>Quick guide:</strong> Pick up a ticket, drive toward the zone with the same color, avoid the wrong ring.</div>
      <div class="callout">Keep the agents moving. If they stall: raise the speed or energy and press Restart.</div>
    </div>
    <div class="mini-callouts">
      <div class="callout">Exploration spikes surface new routes. <strong>Keep epsilon dynamic.</strong></div>
      <div class="callout">Gamma anchors long-term credit. <strong>Watch Q-score stability.</strong></div>
    </div>
  </div>

  <div class="panel-section">
      <h2>Active Policy Network (Best Agent)</h2>
      <canvas id="brainCanvas" width="300" height="150"></canvas>
      <div style="font-size:10px; color:#667; text-align:center">Live Neural Network Activity (Red=Negative, Green=Positive)</div>
  </div>

  <div class="panel-section">
    <h2>Simulation Controls</h2>
    
    <div class="control-group">
      <label>Game Speed: <span id="valSpeed">1x</span></label>
      <input type="range" id="slSpeed" min="1" max="20" value="1">
    </div>

    <div class="control-group">
      <label>Population Size: <span id="valPop">40</span></label>
      <input type="range" id="slPop" min="10" max="100" value="40">
    </div>

    <div class="control-group">
      <label title="Number of tickets in the play area">Ticket Count: <span id="valTickets">15</span></label>
      <input type="range" id="slTicketCount" min="5" max="300" value="15">
    </div>

    <div class="control-group">
      <label>Ticket Spawn Layout</label>
      <select id="slTicketLayout">
        <option value="random">Random (Full Map)</option>
        <option value="lanes">Three Lanes</option>
        <option value="corners">Corner Clusters</option>
      </select>
    </div>

    <div class="control-group">
      <label>Ticket Category Grouping</label>
      <select id="slTicketGrouping">
        <option value="mixed">Mixed</option>
        <option value="grouped">Grouped by Category</option>
      </select>
    </div>
    
    <div class="control-group">
      <label title="Antal frames per episod">Episode Duration (Frames): <span id="valDuration">2500</span></label>
      <input type="range" id="slDuration" min="500" max="10000" step="100" value="2500">
    </div>

    <label class="checkbox-row"><input type="checkbox" id="chkManualEpisode"> Manual Episode (Ends on Restart)</label>
    
    <div class="btn-group">
        <button class="btn alt" id="btnResetAI">Reset Policy Weights</button>
        <button class="btn" id="btnSkip">Restart Episode</button>
    </div>
    <button class="btn danger" id="btnReset">Hard Reset All</button>
  </div>

  <div class="panel-section">
    <h2>RL/Policy Parameters</h2>
    
    <div class="control-group">
      <label title="How quickly the network weights update">Learning Rate (Alpha): <span id="valAlpha">0.010</span></label>
      <input type="range" id="slAlpha" min="1" max="100" value="10" step="1">
    </div>

    <div class="control-group">
        <label title="Weight for future rewards. Higher = more long-term planning">Discount Factor (Gamma): <span id="valGamma">0.90</span></label>
        <input type="range" id="slGamma" min="50" max="99" value="90" step="1">
    </div>
    
    <div class="control-group">
        <label title="Share of random moves for exploration">Exploration Rate (Epsilon): <span id="valEpsilon">15%</span></label>
        <input type="range" id="slEpsilon" min="0" max="50" value="15" step="1">
    </div>
    
    <div class="control-group">
      <label title="Antal noder i dolda lagret.">Hidden Nodes: <span id="valHidden">20</span></label>
      <input type="range" id="slHidden" min="8" max="40" step="4" value="20">
    </div>
  </div>

  <div class="panel-section">
    <h2>Smart Boosts (10)</h2>
    <ul class="smart-list">
      <li><strong>Adaptive ε:</strong> dynamisk exploration som justeras efter precision & stall</li>
      <li><strong>Reward-volatil α:</strong> lärhastighet växer när signaler blir brusiga</li>
      <li><strong>Adaptiv feromondekay:</strong> stabiliserar spår när träffsäkerheten dippar</li>
      <li><strong>Sensor-skalning:</strong> bredare sök när agenten letar, tajtare vid leverans</li>
      <li><strong>Stuck-escape:</strong> automatisk boost när agenten fastnar</li>
      <li><strong>Nyfikenhetsbonus:</strong> belönar nya celler för snabbare områdestäckning</li>
      <li><strong>Progress-streak:</strong> extra reward för stabilt framsteg mot mål</li>
      <li><strong>Leader beacon:</strong> bästa agenten lämnar starkare vägspår</li>
      <li><strong>Success reinforcement:</strong> extra feromon vid korrekt sortering</li>
      <li><strong>Separation steering:</strong> sprider ut agenter för att täcka mer yta</li>
    </ul>
  </div>

  <div class="panel-section">
    <h2>Game Physics / ACO</h2>
    
    <div class="control-group">
      <label title="How far the agents can see">Sensor Range: <span id="valSensor">180px</span></label>
      <input type="range" id="slSensor" min="50" max="400" value="180">
    </div>
    
    <div class="control-group">
      <label title="Higher = batteries drain faster">Battery Drain: <span id="valDrain">Normal</span></label>
      <input type="range" id="slDrain" min="1" max="20" value="8">
    </div>

    <div class="control-group">
      <label title="Evaporation rate for pheromones. 0.99 = slow">Pheromone Decay: <span id="valDecay">0.990</span></label>
      <input type="range" id="slDecay" min="980" max="999" value="990">
    </div>
  </div>
  
  <div class="panel-section">
    <h2>Visuals</h2>
      <label class="checkbox-row"><input type="checkbox" id="chkBrainViz" checked> Show Policy Network</label>
      <label class="checkbox-row"><input type="checkbox" id="chkSensors"> Show Sensors (Simplified)</label>
      <label class="checkbox-row"><input type="checkbox" id="chkPheromones" checked> Show Pheromone Heatmap</label>
      <label class="checkbox-row"><input type="checkbox" id="chkParticles" checked> Show Particles (Feedback)</label>
      <label class="checkbox-row"><input type="checkbox" id="chkTrail"> Show Best Agent Trail</label>
      <div class="pulse-grid" style="margin-top:10px;">
        <div class="pulse-row"><span class="pulse-label">Exploration (ε)</span><div class="pulse-bar"><span id="barEpsilon"></span></div><span class="pulse-value" id="valEpsilonPulse">15%</span></div>
        <div class="pulse-row"><span class="pulse-label">Learning Rate (α)</span><div class="pulse-bar"><span id="barAlpha"></span></div><span class="pulse-value" id="valAlphaPulse">0.010</span></div>
        <div class="pulse-row"><span class="pulse-label">Discount (γ)</span><div class="pulse-bar"><span id="barGamma"></span></div><span class="pulse-value" id="valGammaPulse">0.90</span></div>
      </div>
  </div>
</aside>

<main class="main-view">
  <div class="viewport">
    <div class="sim-top-bar">
        <span><strong style="color:var(--accent)">HPL-ACO:</strong> Hybrid Policy Learning Simulation</span>
        <span class="fps-counter" id="fpsDisplay">FPS: 0</span>
    </div>
    <div class="episode-progress"><div class="fill" id="episodeFill"></div></div>
    <canvas id="simCanvas"></canvas>
    <div class="hud">
      <div class="generation-display" id="hudGen">EPISODE 1</div>
      <div style="text-align:right; font-size:12px; color:rgba(255,255,255,0.4)">
        <p>[SPACE] Pause | [S] Restart Episode | Click & Drag Agent / NEST / Zone</p>
      </div>
    </div>
    <div class="live-feed" id="feed"></div>
    <div id="hoverTip"></div>
    <div class="neon-pulse"></div>
  </div>
</main>

<script>
// --- CONFIGURATION OBJECT (Mutable) ---
const CFG = {
  popSize: 40,
  RL_ALPHA: 0.01, // Learning Rate
  RL_GAMMA: 0.90,  // Discount Factor
  RL_EPSILON: 0.15, // Exploration Rate
  learningMode: 'evolve', // 'rl' or 'evolve' (Foodwars-style evolution)
  evolve: {
    elite: 0.2,
    mutRate: 0.22,
    mutStrength: 0.25,
    fresh: 0.06
  },
  
  ticketCount: 15,
  manualEpisode: false,
  ticketSpawn: {
    layout: 'random',
    grouping: 'mixed'
  },
  sensorRange: 180, 
  maxSpeed: 4.0, 
  turnRate: 0.08, 
  episodeDuration: 2500, 
  energyDrain: 0.0008, 
  
  // Policy Network Architecture (Fixed)
  inputs: 15, 
  hiddens: 20, 
  outputs: 6, 
  // Outputs: [Steer_Bias, Speed_Factor, Brake_Factor, Goal_INC_WT, Goal_REQ_WT, Goal_PROB_WT]
  smart: {
    epsilonMin: 0.02,
    epsilonMax: 0.5,
    alphaMin: 0.002,
    alphaMax: 0.06,
    sensorBoostMax: 1.6,
    carrySensorScale: 0.85,
    stuckFrames: 45,
    curiosityReward: 0.3,
    progressStreakReward: 0.12,
    leaderDeposit: 0.07,
    agentDeposit: 0.04,
    ticketDeposit: 0.08,
    zoneDeposit: 0.12,
    successDeposit: 0.2,
    separationRadius: 35,
    separationStrength: 0.6,
    deliveryAssist: 0.35,
    pheromoneAssist: 0.55
  },
  
  categories: [
    { id: 'incident', color: '#ff3366', label: 'Incident' }, /* Red */
    { id: 'request', color: '#00ff99', label: 'Service Req' }, /* Green */
    { id: 'problem', color: '#00eaff', label: 'Problem' } /* Cyan */
  ]
};

// --- GLOBALS ---
const canvas = document.getElementById('simCanvas');
const ctx = canvas.getContext('2d', { alpha: false });
const brainCanvas = document.getElementById('brainCanvas');
const brainCtx = brainCanvas.getContext('2d');
const hoverTip = document.getElementById('hoverTip');
const fpsDisplay = document.getElementById('fpsDisplay');

let W, H;
let episode = 1;
let frame = 0;
let speedMult = 1;
let paused = false;
let agents = [];
let tickets = [];
let particles = [];
let bestAgent = null; // Agent with the highest accumulated fitness in the current episode
let history = [];
let nest = null; 
let goalZones = []; 
let mouse = { x:0, y:0, down:false, dragAgent:null, dragNest: false, dragZone: null }; 
let zoneHighlight = null; 

// FPS Counter Variables
let lastFrameTime = 0;
let fps = 0;

// Stats
let stats = {
    solved: 0,
    wrong: 0,
    activeCount: 0
};

// --- MATH UTILS ---
const dist = (x1,y1,x2,y2) => Math.hypot(x2-x1, y2-y1);
const clamp = (v,min,max) => Math.max(min, Math.min(max, v));
const rand = (min,max) => Math.random() * (max-min) + min;
const normDist = (d) => clamp(d / CFG.sensorRange, 0, 1); 
const normDistWithRange = (d, range) => clamp(d / range, 0, 1);
const normAngle = (a) => {
    while (a > Math.PI) a -= 2 * Math.PI;
    while (a < -Math.PI) a += 2 * Math.PI;
    return a / Math.PI;
}

// Sigmoid activation function (useful for policy outputs)
const sigmoid = (x) => 1 / (1 + Math.exp(-x));
const tanh = (x) => Math.tanh(x);

// --- FEROMON SYSTEM (ACO) ---
const PHEROMONE_CAP = 10;
const PHEROMONE_SPREAD = 0.4;
let PHEROMONE_DECAY = 0.990; 

let CS = 25; 
let GW = 0; 
let GH = 0; 
let grid = {
    food: null, 
    incident: null, 
    request: null, 
    problem: null, 
};
const GRID_FIELDS = ['food', 'incident', 'request', 'problem'];

const adaptive = {
    epsilon: CFG.RL_EPSILON,
    alpha: CFG.RL_ALPHA,
    decay: PHEROMONE_DECAY,
    successEMA: 0,
    stallEMA: 0,
    rewardEMA: 0,
    rewardVar: 0
};

const getEffectiveEpsilon = () => adaptive.epsilon || CFG.RL_EPSILON;
const getEffectiveAlpha = () => adaptive.alpha || CFG.RL_ALPHA;

const gi=(x,y)=> y*GW + x;
const clampi=(v,a,b)=> v<a?a:(v>b?b:v);

function makeGrid(){
    GW = Math.floor(W / CS);
    GH = Math.floor(H / CS);
    const size = GW * GH;
    
    for(const key of GRID_FIELDS){
        grid[key] = new Float32Array(size); 
    }
}

function deposit(type, x, y, amt, opts = {}){
    const field = grid?.[type];
    if(!field) return;
    const amount = Number(amt);
    if(!Number.isFinite(amount) || amount <= 0) return;
    
    const cx=clampi((x/CS)|0,0,GW-1), cy=clampi((y/CS)|0,0,GH-1);
    const idx = gi(cx,cy);
    const cap = Number.isFinite(opts.cap) ? opts.cap : PHEROMONE_CAP;
    
    const apply = (index, delta)=>{ 
        if(index<0 || index>=field.length) return;
        let next = field[index] + delta;
        field[index] = Math.min(next, cap);
    }; 
    
    apply(idx, amount);
    
    const spread = Math.max(0, Number(opts.spread)||0);
    if(spread > 0) {
         const dx = [-1, 0, 1, -1, 1, -1, 0, 1];
         const dy = [-1, -1, -1, 0, 0, 1, 1, 1];
         const spreadAmt = amount * spread * 0.1;
         for(let i=0; i<8; i++){
             const ncx = cx + dx[i];
             const ncy = cy + dy[i];
             const nidx = gi(clampi(ncx,0,GW-1), clampi(ncy,0,GH-1));
             apply(nidx, spreadAmt);
         }
    }
}

// Calculates the pheromone gradient (scent direction) at a position
function senseGrad(type, x, y){
    const field = grid?.[type];
    if(!field) return { gx: 0, gy: 0, mag: 0 };
    
    const cx=clampi((x/CS)|0,0,GW-1), cy=clampi((y/CS)|0,0,GH-1);
    
    let gx = 0;
    let gy = 0;
    let centerVal = field[gi(cx,cy)];

    if(centerVal > 0){
        const dx = [1, 1, 1, 0, 0, -1, -1, -1];
        const dy = [-1, 0, 1, -1, 1, -1, 0, 1];
        const scale = [0.5, 1, 0.5, 1, 1, 0.5, 1, 0.5]; 

        for(let i=0; i<8; i++){
            const ncx = cx + dx[i];
            const ncy = cy + dy[i];
            
            const nidx = gi(clampi(ncx,0,GW-1), clampi(ncy,0,GH-1));
            const neighborVal = field[nidx];
            
            const diff = neighborVal - centerVal; 

            gx += dx[i] * diff * scale[i];
            gy += dy[i] * diff * scale[i];
        }
    }

    const mag = Math.hypot(gx, gy);
    if(mag > 0){
        gx /= mag;
        gy /= mag;
    }

    return { gx, gy, mag: centerVal }; 
}

function evaporate(){
    const decay = adaptive.decay || PHEROMONE_DECAY;
    for(let i=0; i<grid.food.length; i++){
        for(const key of GRID_FIELDS){
            grid[key][i] *= decay;
        }
    }
}

// --- END FEROMON SYSTEM ---


// --- POLICY NETWORK (RL Component) ---

class PolicyNetwork {
    constructor(inputs, hiddens, outputs, weights = null) {
        this.I = inputs;
        this.H = hiddens;
        this.O = outputs;
        
        const size1 = this.I * this.H;
        const size2 = this.H * this.O;

        // Initialize or clone weights and biases
        this.w1 = weights ? new Float32Array(weights.w1) : new Float32Array(size1).map(() => rand(-0.5, 0.5));
        this.w2 = weights ? new Float32Array(weights.w2) : new Float32Array(size2).map(() => rand(-0.5, 0.5));
        this.bias1 = weights ? new Float32Array(weights.bias1) : new Float32Array(this.H).map(() => rand(-0.5, 0.5));
        this.bias2 = weights ? new Float32Array(weights.bias2) : new Float32Array(this.O).map(() => rand(-0.5, 0.5));

        // For backpropagation: Store activations and Z-values (pre-activation)
        this.hiddens = new Float32Array(this.H);
        this.outputs = new Float32Array(this.O);
        this.z1 = new Float32Array(this.H);
        this.z2 = new Float32Array(this.O);
    }

    clone() {
        return new PolicyNetwork(this.I, this.H, this.O, {
            w1: this.w1, w2: this.w2, bias1: this.bias1, bias2: this.bias2
        });
    }

    mutate(rate, strength) {
        for(let i=0; i<this.w1.length; i++) {
            if(Math.random() < rate) this.w1[i] += rand(-strength, strength);
        }
        for(let i=0; i<this.w2.length; i++) {
            if(Math.random() < rate) this.w2[i] += rand(-strength, strength);
        }
        for(let i=0; i<this.bias1.length; i++) {
            if(Math.random() < rate) this.bias1[i] += rand(-strength, strength);
        }
        for(let i=0; i<this.bias2.length; i++) {
            if(Math.random() < rate) this.bias2[i] += rand(-strength, strength);
        }
    }

    // Forward pass - Maps state (inputs) to action policy (outputs)
    predict(inputs) {
        const safeInputs = new Float32Array(this.I);
        for(let i=0; i<this.I; i++) safeInputs[i] = inputs[i] || 0;

        // Hidden Layer (Tanh activation)
        for(let i=0; i<this.H; i++) {
            let sum = this.bias1[i];
            for(let j=0; j<this.I; j++) sum += safeInputs[j] * this.w1[j*this.H + i];
            this.z1[i] = sum;
            this.hiddens[i] = tanh(sum);
        }

        // Output Layer (Tanh for Action Weights)
        for(let i=0; i<this.O; i++) {
            let sum = this.bias2[i];
            for(let j=0; j<this.H; j++) sum += this.hiddens[j] * this.w2[j*this.O + i];
            this.z2[i] = sum;
            this.outputs[i] = tanh(sum); // Policy is [-1, 1]
        }
        return { outputs: this.outputs, hiddens: this.hiddens };
    }

    // Simplified Policy Gradient/Online Learning Update
    // Reward (R) acts as the 'Advantage' estimate.
    backpropagate(inputs, outputs, reward, alpha) {
        if(reward === 0) return; // Skip learning if no reward

        const learningRate = alpha * Math.abs(reward); // Scale learning by reward magnitude
        
        // 1. Calculate Output Gradients (Policy update proportional to reward)
        let outputDeltas = new Float32Array(this.O);
        for(let i=0; i<this.O; i++) {
             // Derivative of tanh(x) is 1 - tanh(x)^2.
             const activation_derivative = 1 - outputs[i] * outputs[i];
             // Simple pseudo-gradient: (Reward Signal) * (Activation Derivative)
             outputDeltas[i] = reward * activation_derivative; 
        }

        // 2. Calculate Hidden Deltas
        let hiddenDeltas = new Float32Array(this.H);
        for(let i=0; i<this.H; i++) {
            let sum = 0;
            for(let j=0; j<this.O; j++) {
                sum += outputDeltas[j] * this.w2[i*this.O + j];
            }
            // Derivative of tanh(x) is 1 - tanh(x)^2.
            hiddenDeltas[i] = sum * (1 - this.hiddens[i] * this.hiddens[i]);
        }
        
        // 3. Update Weights (Hidden -> Output)
        for(let i=0; i<this.H; i++) {
            for(let j=0; j<this.O; j++) {
                const index = i*this.O + j;
                this.w2[index] += learningRate * outputDeltas[j] * this.hiddens[i];
            }
        }
        // Update Biases (Output)
        for(let i=0; i<this.O; i++) {
            this.bias2[i] += learningRate * outputDeltas[i];
        }

        // 4. Update Weights (Input -> Hidden)
        const safeInputs = new Float32Array(this.I);
        for(let i=0; i<this.I; i++) safeInputs[i] = inputs[i] || 0;
        
        for(let i=0; i<this.I; i++) {
            for(let j=0; j<this.H; j++) {
                const index = i*this.H + j;
                this.w1[index] += learningRate * hiddenDeltas[j] * safeInputs[i];
            }
        }
        // Update Biases (Hidden)
        for(let i=0; i<this.H; i++) {
            this.bias1[i] += learningRate * hiddenDeltas[i];
        }
    }
}


// --- ENTITIES ---
class Nest {
    // ... (Nest class remains the same) ...
    constructor(x, y) {
        this.x = x;
        this.y = y;
        this.r = 25;
    }
    draw() {
        const pulseR = this.r * (1 + Math.sin(frame * 0.1) * 0.1);
        ctx.strokeStyle = 'rgba(255, 255, 255, 0.1)';
        ctx.lineWidth = 1;
        ctx.beginPath();
        ctx.arc(this.x, this.y, pulseR + 5, 0, Math.PI * 2);
        ctx.stroke();

        ctx.fillStyle = 'rgba(255, 255, 255, 0.08)';
        ctx.strokeStyle = 'rgba(255, 255, 255, 0.4)';
        ctx.lineWidth = 2;
        ctx.beginPath();
        ctx.arc(this.x, this.y, this.r, 0, Math.PI * 2);
        ctx.fill();
        ctx.stroke();
        
        ctx.fillStyle = '#fff';
        ctx.textAlign = 'center';
        ctx.font = '12px ' + varStyles.fontUi;
        ctx.fillText('NEST', this.x, this.y + 4);
        
        if (mouse.dragNest) {
            ctx.strokeStyle = varStyles.accent;
            ctx.lineWidth = 3;
            ctx.beginPath();
            ctx.arc(this.x, this.y, this.r + 5, 0, Math.PI * 2);
            ctx.stroke();
        }
        
        // Feromon Deposition (Food/Nest Pheromone) at the Nest
        if(frame % 5 === 0) {
            deposit('food', this.x, this.y, PHEROMONE_CAP * 0.05, { cap: PHEROMONE_CAP, spread: 0.1 });
        }
    }
}

class Ticket {
    // ... (Ticket class remains the same) ...
    constructor() { this.respawn(); }

    update() {
        this.x += Math.sin(frame * 0.05 + this.id) * 0.2;
        this.y += Math.cos(frame * 0.05 + this.id) * 0.2;
        
        this.life -= this.decay;
        if(this.life <= 0) {
            spawnParticles(this.x, this.y, '#555', 5);
            this.respawn();
        }

        deposit('food', this.x, this.y, PHEROMONE_CAP * CFG.smart.ticketDeposit, { spread: PHEROMONE_SPREAD });
    }

    respawn() {
        this.id = Math.random();
        this.typeIdx = Math.floor(Math.random() * CFG.categories.length);
        this.def = CFG.categories[this.typeIdx];
        const spawn = getTicketSpawnPoint(this.typeIdx);
        this.x = spawn.x;
        this.y = spawn.y;
        this.life = 1.0;
        this.decay = rand(0.0002, 0.0008); 
        this.r = 8;
    }

    draw() {
        const w = 12, h = 16;
        ctx.save();
        ctx.translate(this.x, this.y);

        const badge = ctx.createLinearGradient(-w/2, -h/2, w/2, h/2);
        badge.addColorStop(0, this.def.color);
        badge.addColorStop(1, 'rgba(255,255,255,0.7)');
        ctx.fillStyle = badge;
        ctx.globalAlpha = 0.9;
        ctx.beginPath();
        ctx.roundRectPolyfill(-w/2, -h/2, w, h, 3);
        ctx.fill();
        ctx.globalAlpha = 1;

        ctx.fillStyle = '#fff';
        ctx.fillRect(-w/2 + 1, -h/2 + 1, (w-2) * this.life, 2);

        ctx.strokeStyle = '#fff';
        ctx.lineWidth = 1;
        ctx.stroke();

        ctx.restore();
    }
}


class Agent {
  constructor(policy = null) {
    this.policy = policy || new PolicyNetwork(CFG.inputs, CFG.hiddens, CFG.outputs);
    this.x = nest ? nest.x : W/2; 
    this.y = nest ? nest.y : H/2; 
    this.angle = rand(0, Math.PI*2);
    this.vel = 0;
    this.r = 10;
    this.teamHue = 210; 
    this.carrying = null;
    this.energy = 1.0;
    this.fitness = 0;
    this.stalled = false;
    this.trail = []; 
    
    // RL State Variables
    this.lastState = new Array(CFG.inputs).fill(0); 
    this.lastAction = new Array(CFG.outputs).fill(0);
    this.accumulatedReward = 0;
    this.qScore = 0; // Accumulated Q-score / long-term fitness
    this.stuckFrames = 0;
    this.searchFrames = 0;
    this.progressStreak = 0;
    this.visitedCells = new Set();
    this.lastSensorRange = CFG.sensorRange;
  }

  getSensorRange() {
    const baseRange = CFG.sensorRange;
    let range = baseRange;
    if (this.carrying) {
        range *= CFG.smart.carrySensorScale;
    } else {
        const boost = clamp(this.searchFrames / 900, 0, CFG.smart.sensorBoostMax - 1);
        range *= 1 + boost;
    }
    return clamp(range, baseRange * 0.7, baseRange * CFG.smart.sensorBoostMax);
  }
  
  // Gets the current state (inputs) for the Policy Network
  getState() {
    let inputs = new Array(CFG.inputs).fill(0);
    let inputIndex = 0;
    const effectiveRange = this.getSensorRange();
    this.lastSensorRange = effectiveRange;

    const toVector = (target) => {
        if (!target) return { dx: 0, dy: 0, dist: 1 };
        const dx = clamp((target.x - this.x) / effectiveRange, -1, 1);
        const dy = clamp((target.y - this.y) / effectiveRange, -1, 1);
        const normalizedDist = clamp(dist(this.x, this.y, target.x, target.y) / effectiveRange, 0, 1);
        return { dx, dy, dist: normalizedDist };
    };

    const zones = getZones();
    const incidentZone = zones.find(z => z.id === 'incident');
    const requestZone = zones.find(z => z.id === 'request');
    const problemZone = zones.find(z => z.id === 'problem');

    // 1. Closest Ticket Vector (2 inputs)
    let closestTicket = null;
    let closestTicketDist = Infinity;
    if(!this.carrying) {
        for(let t of tickets) {
            if(t.x < 0) continue; 
            const d = dist(this.x, this.y, t.x, t.y);
            if (d < closestTicketDist) {
                closestTicketDist = d;
                closestTicket = t;
            }
        }
    }
    const ticketVector = toVector(closestTicket);
    inputs[inputIndex++] = ticketVector.dx;
    inputs[inputIndex++] = ticketVector.dy;

    // 2. Goal Zone Vectors (6 inputs)
    const incidentVector = toVector(incidentZone);
    const requestVector = toVector(requestZone);
    const problemVector = toVector(problemZone);
    inputs[inputIndex++] = incidentVector.dx;
    inputs[inputIndex++] = incidentVector.dy;
    inputs[inputIndex++] = requestVector.dx;
    inputs[inputIndex++] = requestVector.dy;
    inputs[inputIndex++] = problemVector.dx;
    inputs[inputIndex++] = problemVector.dy;

    // 3. Wall Sensor (1 input)
    let minDistToWall = Infinity;
    const distToLeft = this.x;
    const distToRight = W - this.x;
    const distToTop = this.y;
    const distToBottom = H - this.y;
    minDistToWall = Math.min(distToLeft, distToRight, distToTop, distToBottom);

    inputs[inputIndex++] = normDistWithRange(minDistToWall, effectiveRange); 

    // 4. Carrying Info (3 inputs)
    if(this.carrying) {
      inputs[inputIndex++] = this.carrying.def.id === 'incident' ? 1:0; 
      inputs[inputIndex++] = this.carrying.def.id === 'request' ? 1:0; 
      inputs[inputIndex++] = this.carrying.def.id === 'problem' ? 1:0; 
    } else {
      inputs[inputIndex++] = 0;
      inputs[inputIndex++] = 0;
      inputs[inputIndex++] = 0;
    }
    
    // 5. Status (2 inputs)
    inputs[inputIndex++] = this.energy;                   
    inputs[inputIndex++] = this.vel / CFG.maxSpeed;       

    // 6. Ticket Distance (1 input)
    inputs[inputIndex++] = ticketVector.dist;
    
    return inputs;
  }
  
  // Core Policy/Action Execution
  executeAction(policyOutputs) {
    // outputs: [Steer_Bias, Speed_Factor, Brake_Factor, Goal_INC_WT, Goal_REQ_WT, Goal_PROB_WT]
    const steerBias = policyOutputs[0]; // [-1, 1] - Left/Right preference
    const speedFactor = (policyOutputs[1] + 1) / 2; // [0, 1]
    const brakeFactor = (policyOutputs[2] + 1) / 2; // [0, 1]
    const incidentWeight = (policyOutputs[3] + 1) / 2; // [0, 1]
    const requestWeight = (policyOutputs[4] + 1) / 2; // [0, 1]
    const problemWeight = (policyOutputs[5] + 1) / 2; // [0, 1]

    // 1. Calculate Desired Steering Angle (ACO + Policy)
    let desiredAngle = this.angle;
    let turnMag = 0;
    
    // Convert target vectors to an angle
    const zones = getZones();
    const incidentZone = zones.find(z => z.id === 'incident');
    const requestZone = zones.find(z => z.id === 'request');
    const problemZone = zones.find(z => z.id === 'problem');

    let targetVec = { x: 0, y: 0 };
    if (this.carrying) {
        const correctZone = zones.find(z => z.id === this.carrying.def.id);
        if (correctZone) {
            targetVec.x = correctZone.x - this.x;
            targetVec.y = correctZone.y - this.y;
        }
    } else {
        let closestTicket = null;
        let closestTicketDist = Infinity;
        for(let t of tickets) {
            if(t.x < 0) continue; 
            const d = dist(this.x, this.y, t.x, t.y);
            if (d < closestTicketDist) {
                closestTicketDist = d;
                closestTicket = t;
            }
        }
        if (closestTicket) {
            targetVec.x = closestTicket.x - this.x;
            targetVec.y = closestTicket.y - this.y;
        }
    }

    const pheromoneType = this.carrying ? this.carrying.def.id : 'food';
    const pheromoneGrad = senseGrad(pheromoneType, this.x, this.y);
    if (pheromoneGrad.mag > 0) {
        const assistScale = CFG.smart.pheromoneAssist * CFG.sensorRange;
        targetVec.x += pheromoneGrad.gx * assistScale;
        targetVec.y += pheromoneGrad.gy * assistScale;
    }

    const targetMag = Math.hypot(targetVec.x, targetVec.y);
    
    // Weighted steering combination
    if (targetMag > 0.05) {
        desiredAngle = Math.atan2(targetVec.y, targetVec.x);
        
        // Calculate the difference between current angle and desired angle
        let angleDiff = desiredAngle - this.angle;
        angleDiff = normAngle(angleDiff * Math.PI) * Math.PI; // Normalize to [-PI, PI]
        
        turnMag = angleDiff;
    } 

    // Add Policy Steering Bias
    turnMag += steerBias * 0.5; // Policy can push the steering left/right

    // Separation steering to spread agents out
    let separationTurn = 0;
    for (const other of agents) {
        if (other === this) continue;
        const d = dist(this.x, this.y, other.x, other.y);
        if (d > 0 && d < CFG.smart.separationRadius) {
            const awayAngle = Math.atan2(this.y - other.y, this.x - other.x);
            const diff = normAngle(awayAngle - this.angle) * Math.PI;
            separationTurn += diff * ((CFG.smart.separationRadius - d) / CFG.smart.separationRadius);
        }
    }
    turnMag += separationTurn * CFG.smart.separationStrength;
    
    // Apply Turning
    this.angle += clamp(turnMag, -CFG.turnRate, CFG.turnRate);
    
    // 2. Propulsion
    let netThrust = speedFactor; // Always try to move forward based on policy output
    if (this.carrying && targetMag > 15) {
        netThrust = clamp(netThrust + 0.15, 0, 1);
    }

    if(this.energy > 0) {
        this.vel += netThrust * 0.3;
        this.energy -= CFG.energyDrain * (1 + netThrust * 2); 
    } else {
        this.stalled = true;
    }

    // 3. Braking / Friction
    if (brakeFactor > 0.1) {
        this.vel *= (1 - brakeFactor * 0.2); 
        this.energy -= CFG.energyDrain * 0.5; 
    } else {
        this.vel *= 0.92; 
    }

    this.vel = clamp(this.vel, -CFG.maxSpeed, CFG.maxSpeed);
    
    if(Math.abs(this.vel) < 0.1) {
        this.vel = 0;
        this.energy = Math.min(1, this.energy + 0.02); 
    }

    this.x += Math.cos(this.angle) * this.vel;
    this.y += Math.sin(this.angle) * this.vel;
  }

  // RL Learning Step (Called after Action Execution)
  learn(prevState, prevAction, reward, newPolicyOutputs) {
    if (CFG.learningMode !== 'rl' || reward === 0) return;
    
    const alpha = getEffectiveAlpha();
    const gamma = CFG.RL_GAMMA;

    // The accumulated Q-Score is updated using a simple temporal difference update.
    // Q(S, A) = Q(S, A) + alpha * [ R + gamma * Q_max(S') - Q(S, A) ]
    // Since we don't store Q(S,A) explicitly, we use the immediate reward and update the network.
    
    // Update Agent's long-term score
    this.qScore = this.qScore * gamma + reward; 

    // Backpropagate using the reward as the Advantage/Loss signal
    this.policy.backpropagate(prevState, prevAction, reward, alpha);
  }

  update() {
    if(mouse.dragAgent === this || mouse.dragNest || mouse.dragZone) return; 

    if (this.carrying) {
        this.searchFrames = 0;
    } else {
        this.searchFrames += 1;
    }

    const prevState = this.getState();
    let prevProgressDist = null;
    
    // --- Policy Prediction & Exploration (Epsilon-Greedy) ---
    let policyOutputs;
    let hiddens;
    let reward = 0;

    if(this.carrying) {
        const targetZone = getZones().find(z => z.id === this.carrying.def.id);
        if(targetZone) prevProgressDist = dist(this.x, this.y, targetZone.x, targetZone.y);
    } else {
        let closestTicket = Infinity;
        tickets.forEach(t => {
            if(t.x < 0) return;
            closestTicket = Math.min(closestTicket, dist(this.x, this.y, t.x, t.y));
        });
        prevProgressDist = closestTicket;
    }

    if (Math.random() < getEffectiveEpsilon()) {
        // Exploration: Random Action
        policyOutputs = new Array(CFG.outputs).fill(0).map(() => rand(-1, 1));
        hiddens = new Array(CFG.hiddens).fill(0); 
    } else {
        // Exploitation: Policy Network Action
        const { outputs, hiddens: h } = this.policy.predict(prevState);
        policyOutputs = Array.from(outputs);
        hiddens = h;
    }
    
    this.lastState = prevState;
    this.lastAction = policyOutputs;
    this.lastHiddens = hiddens;
    this.lastOutputs = policyOutputs; 

    // --- Execute Action ---
    const prevX = this.x, prevY = this.y;
    this.executeAction(policyOutputs);
    const postX = this.x, postY = this.y;
    
    // --- Calculate Reward ($R_t$) ---
    const movementReward = dist(prevX, prevY, postX, postY) * 0.15;
    reward += movementReward;

    const movedDist = dist(prevX, prevY, postX, postY);
    if (movedDist < 0.2) {
        this.stuckFrames += 1;
    } else {
        this.stuckFrames = 0;
    }

    const cellX = clampi((this.x / CS) | 0, 0, GW - 1);
    const cellY = clampi((this.y / CS) | 0, 0, GH - 1);
    const cellIdx = gi(cellX, cellY);
    if (!this.visitedCells.has(cellIdx)) {
        this.visitedCells.add(cellIdx);
        reward += CFG.smart.curiosityReward;
    }

    // Dense shaping: reward moving toward target ticket/zone
    if(Number.isFinite(prevProgressDist)) {
        let newProgressDist = prevProgressDist;
        if(this.carrying) {
            const targetZone = getZones().find(z => z.id === this.carrying.def.id);
            if(targetZone) newProgressDist = dist(this.x, this.y, targetZone.x, targetZone.y);
        } else {
            let closestTicket = Infinity;
            tickets.forEach(t => {
                if(t.x < 0) return;
                closestTicket = Math.min(closestTicket, dist(this.x, this.y, t.x, t.y));
            });
            newProgressDist = closestTicket;
        }

        const progressDelta = (prevProgressDist - newProgressDist) || 0;
        const progressBoost = this.carrying ? 0.6 : 0.35;
        reward += progressDelta * progressBoost;

        if (progressDelta > 0.05) {
            this.progressStreak = clamp(this.progressStreak + 1, -8, 8);
        } else if (progressDelta < -0.05) {
            this.progressStreak = clamp(this.progressStreak - 1, -8, 8);
        } else {
            this.progressStreak *= 0.95;
        }
        reward += this.progressStreak * CFG.smart.progressStreakReward;
    }
    
    // Bounds (Wall Bounce)
    if(this.x < this.r || this.x > W-this.r || this.y < this.r || this.y > H-this.r) {
      this.x = clamp(this.x, this.r, W-this.r);
      this.y = clamp(this.y, this.r, H-this.r);
      this.vel *= -0.5;
      reward -= 10; // Stronger wall penalty
    }

    if(this.stalled) {
        reward -= 0.5;
    }
    
    // --- Interactions (Source of Major Rewards/Penalties) ---
    if(!this.carrying) {
      // Try to pick up ticket
      for(let t of tickets) {
        if(dist(this.x, this.y, t.x, t.y) < this.r + 5 && t.x > 0) {
          this.carrying = t;
          t.x = -1000;
          this.searchFrames = 0;
          pushFeed(`Picked up ${t.def.label}`, 'good');
          reward += 10; 
          zoneHighlight = { id: t.def.id, frame: frame }; 
          break;
        }
      }
    } else {
      // Try to drop off ticket
      const zones = getZones();
      for(let z of zones) {
        if(dist(this.x, this.y, z.x, z.y) < z.r) {
          if(z.id === this.carrying.def.id) {
            const urgencyFactor = 1 / this.carrying.decay; 
            const baseReward = 50 + (this.energy * 10);
            reward += baseReward + (baseReward * urgencyFactor * 0.05);
            this.energy = clamp(this.energy + 0.2, 0, 1);

            stats.solved++;
            spawnParticles(this.x, this.y, z.color, 15);
            deposit(z.id, z.x, z.y, PHEROMONE_CAP * CFG.smart.successDeposit, { spread: PHEROMONE_SPREAD });
            pushFeed(`Sorted: ${this.carrying.def.label}`, 'good');
          } else {
            reward -= 50; // MUCH stronger penalty for wrong sorting
            stats.wrong++;
            spawnParticles(this.x, this.y, varStyles.accentBad, 8);
            pushFeed(`Wrong Zone!`, 'bad');
          }
          this.carrying.respawn();
          this.carrying = null;
          break;
        }
      }
    }

    if (this.stuckFrames > CFG.smart.stuckFrames) {
        this.angle += rand(-1.5, 1.5);
        this.vel = clamp(this.vel + 1.2, -CFG.maxSpeed, CFG.maxSpeed);
        this.energy = clamp(this.energy + 0.1, 0, 1);
        this.stuckFrames = 0;
        reward += 1;
    }
    
    this.accumulatedReward = reward; // Store for display/debugging
    this.fitness += reward; // Overall episode fitness (for finding best agent)
    this.qScore = this.fitness; // Keep Q-score display in sync with fitness for evolve mode
    
    // --- Learning Step (RL) ---
    this.learn(prevState, policyOutputs, reward, policyOutputs); 

    // Trail update
    if(this === bestAgent && document.getElementById('chkTrail')?.checked) {
        this.trail.push({ x: this.x, y: this.y, alpha: 1.0 });
        if(this.trail.length > 50) this.trail.shift(); 
    } else if (this !== bestAgent) {
        this.trail = [];
    }
  }

  // Draw simplified sensor line to closest wall/ticket if enabled
  drawSensors() {
      if(!document.getElementById('chkSensors')?.checked) return;
      
      const inputs = this.lastState;
      const wallInput = inputs[13]; 
      const ticketDistInput = inputs[14]; 
      const sensorRange = this.lastSensorRange || CFG.sensorRange;

      ctx.globalAlpha = 0.5;
      ctx.lineWidth = 1;

      if (wallInput < 1) {
        const wallRange = wallInput * sensorRange;
        ctx.strokeStyle = varStyles.accentBad;
        ctx.beginPath();
        ctx.arc(this.x, this.y, wallRange, 0, Math.PI * 2);
        ctx.stroke();
      }
      
      if (ticketDistInput < 1 && ticketDistInput > 0) {
        const ticketRange = ticketDistInput * sensorRange;
        ctx.strokeStyle = varStyles.accentOk;
        ctx.beginPath();
        ctx.arc(this.x, this.y, ticketRange, 0, Math.PI * 2);
        ctx.stroke();
      }
      
      ctx.globalAlpha = 1;
  }


  draw() {
    this.drawSensors();
    if(this.carrying) this.drawCarryingLink();

    ctx.save();
    ctx.translate(this.x, this.y);
    ctx.rotate(this.angle);

    // Thruster trail
    ctx.globalAlpha = 0.5;
    const flame = ctx.createLinearGradient(-this.r*2, 0, 0, 0);
    flame.addColorStop(0, 'rgba(56,189,248,0)');
    flame.addColorStop(1, 'rgba(56,189,248,0.7)');
    ctx.fillStyle = flame;
    ctx.beginPath();
    ctx.moveTo(-this.r*2.2, -2);
    ctx.lineTo(-this.r*0.8, 0);
    ctx.lineTo(-this.r*2.2, 2);
    ctx.fill();
    ctx.globalAlpha = 1;

    if(this === bestAgent) {
        ctx.save();
        ctx.rotate(-this.angle);
        ctx.globalAlpha = 0.5 + Math.sin(frame*0.15)*0.25;
        ctx.strokeStyle = '#ffd700';
        ctx.lineWidth = 2.5;
        ctx.beginPath();
        ctx.arc(0, 0, this.r + 6, 0, Math.PI*2);
        ctx.stroke();
        ctx.restore();
    }

    let ringColor = this.energy > 0.3 ? varStyles.accentOk : (this.stalled ? varStyles.accentBad : '#ff9900');
    if(this.energy < 0.3) {
        ctx.globalAlpha = 0.5 + Math.sin(frame * 0.2) * 0.5;
        ctx.lineWidth = 3;
    } else {
        ctx.lineWidth = 1.5;
        ctx.globalAlpha = 1;
    }
    ctx.beginPath();
    ctx.arc(0, 0, this.r + 3, 0, Math.PI * 2 * this.energy);
    ctx.strokeStyle = ringColor;
    ctx.stroke();
    
    ctx.globalAlpha = 1;
    
    let agentFillColor;
    if (this.carrying) {
        agentFillColor = this.carrying.def.color;
    } else {
        // Color based on policy's 'memory' (normalized Q-Score)
        const memSaturation = 50 + clamp(this.qScore / 100, 0, 100); 
        agentFillColor = `hsl(${this.teamHue}, ${memSaturation}%, 50%)`;
    }

    ctx.fillStyle = this.stalled ? '#552222' : agentFillColor;
    
    if(this === bestAgent) {
        ctx.shadowBlur = 10;
        ctx.shadowColor = '#ffffaa';
        ctx.fillStyle = '#fff';
    }

    ctx.beginPath();
    ctx.moveTo(this.r * 1.5, 0); 
    ctx.lineTo(-this.r, this.r * 0.8); 
    ctx.lineTo(-this.r * 0.5, 0); 
    ctx.lineTo(-this.r, -this.r * 0.8); 
    ctx.closePath();
    ctx.fill();

    ctx.shadowBlur = 0;

    ctx.restore();
  }

  drawCarryingLink() {
      if(!this.carrying || this.carrying.x > -100) return; 
      
      const zones = getZones();
      const targetZone = zones.find(z => z.id === this.carrying.def.id);
      if(!targetZone) return;

      const gradient = ctx.createLinearGradient(this.x, this.y, targetZone.x, targetZone.y);
      gradient.addColorStop(0, this.carrying.def.color);
      gradient.addColorStop(1, 'rgba(255,255,255,0.05)');
      
      ctx.strokeStyle = gradient;
      ctx.lineWidth = 2;
      ctx.setLineDash([5, 5]); 
      ctx.lineDashOffset = -frame * 0.5; 
      ctx.globalAlpha = 0.5;

      ctx.beginPath();
      ctx.moveTo(this.x, this.y);
      ctx.lineTo(targetZone.x, targetZone.y);
      ctx.stroke();

      ctx.setLineDash([]);
      ctx.lineDashOffset = 0;
      ctx.globalAlpha = 1;
  }
}

// --- SYSTEM ---

// Utility for roundRect (Compatibility for older browsers/environments)
if (!CanvasRenderingContext2D.prototype.roundRectPolyfill) {
    CanvasRenderingContext2D.prototype.roundRectPolyfill = function(x, y, w, h, r) {
        if (typeof r === 'number') r = { tl: r, tr: r, br: r, bl: r };
        else r = { ...{ tl: 0, tr: 0, br: 0, bl: 0 }, ...r };
        this.moveTo(x + r.tl, y);
        this.lineTo(x + w - r.tr, y);
        this.arcTo(x + w, y, x + w, y + r.tr, r.tr);
        this.lineTo(x + w, y + h - r.br);
        this.arcTo(x + w, y + h, x + w - r.br, y + h, r.br);
        this.lineTo(x + r.bl, y + h);
        this.arcTo(x, y + h, x, y + h - r.bl, r.bl);
        this.lineTo(x, y + r.tl);
        this.arcTo(x, y, x + r.tl, y, r.tl);
        this.closePath();
    };
}

const varStyles = {
    fontUi: getComputedStyle(document.documentElement).getPropertyValue('--font-ui').trim(),
    accent: getComputedStyle(document.documentElement).getPropertyValue('--accent').trim(),
    accentOk: getComputedStyle(document.documentElement).getPropertyValue('--accent-ok').trim(),
    accentBad: getComputedStyle(document.documentElement).getPropertyValue('--accent-bad').trim(),
    textDim: getComputedStyle(document.documentElement).getPropertyValue('--text-dim').trim(),
};


function getZones() {
  return goalZones; 
}

function drawZones() {
    // ... (drawZones remains the same) ...
  getZones().forEach(z => {
    if (zoneHighlight && z.id === zoneHighlight.id && frame < zoneHighlight.frame + 30) {
        ctx.globalAlpha = (Math.sin(frame*0.2) + 1.5) * 0.3; 
        ctx.strokeStyle = '#fff';
        ctx.lineWidth = 5;
        ctx.beginPath(); ctx.arc(z.x, z.y, z.r + 5, 0, Math.PI*2); ctx.stroke();
    }
    
    if (mouse.dragZone === z) { 
        ctx.globalAlpha = 1;
        ctx.strokeStyle = '#fff';
        ctx.lineWidth = 4;
        ctx.beginPath();
        ctx.arc(z.x, z.y, z.r + 5, 0, Math.PI * 2);
        ctx.stroke();
    }
    
    const grad = ctx.createRadialGradient(z.x, z.y, z.r*0.2, z.x, z.y, z.r);
    grad.addColorStop(0, z.color + '80'); 
    grad.addColorStop(1, 'transparent');
    ctx.fillStyle = grad; 
    ctx.globalAlpha = 0.5;
    ctx.beginPath(); ctx.arc(z.x, z.y, z.r, 0, Math.PI*2); ctx.fill();
    
    ctx.globalAlpha = 1; 
    ctx.strokeStyle = z.color; 
    ctx.lineWidth = 2; 
    ctx.beginPath(); ctx.arc(z.x, z.y, z.r, 0, Math.PI*2); ctx.stroke();

    ctx.fillStyle = '#fff'; 
    ctx.textAlign = 'center'; 
    ctx.font = '14px ' + varStyles.fontUi;
    ctx.fillText(z.label, z.x, z.y + 5);
  });
  ctx.globalAlpha = 1;
}

function drawAgentTrail() {
    if(!bestAgent || !document.getElementById('chkTrail')?.checked) return;
    
    ctx.lineWidth = 2;
    ctx.beginPath();
    
    bestAgent.trail.forEach((p, i) => {
        const alpha = (i / bestAgent.trail.length) * 0.5;
        ctx.strokeStyle = `rgba(255, 215, 0, ${alpha})`;
        
        if(i === 0) ctx.moveTo(p.x, p.y);
        else {
            const prev = bestAgent.trail[i-1];
            ctx.beginPath();
            ctx.moveTo(prev.x, prev.y);
            ctx.lineTo(p.x, p.y);
            ctx.stroke();
        }
    });
    ctx.globalAlpha = 1;
}

function spawnParticles(x, y, color, count) {
    // ... (spawnParticles remains the same) ...
  if(!document.getElementById('chkParticles')?.checked) return;
  for(let i=0; i<count; i++) {
    particles.push({ 
        x, y, 
        vx: rand(-2, 2), 
        vy: rand(-2, 2), 
        life: 1.0, 
        color, 
        size: rand(2, 5) 
    });
  }
}

function updateParticles() {
    // ... (updateParticles remains the same) ...
  for(let i=particles.length-1; i>=0; i--) {
    let p = particles[i];
    p.x += p.vx * p.life; 
    p.y += p.vy * p.life;
    p.life -= 0.03; 
    if(p.life <= 0) particles.splice(i, 1);
  }
}

function drawParticles() {
    // ... (drawParticles remains the same) ...
  particles.forEach(p => {
    ctx.globalAlpha = p.life;
    ctx.fillStyle = p.color;
    ctx.fillRect(p.x, p.y, p.size, p.size);
  });
  ctx.globalAlpha = 1;
}

function drawPheromones() {
    // ... (drawPheromones remains the same) ...
  if(!document.getElementById('chkPheromones')?.checked) return;

  const maxPh = PHEROMONE_CAP;
  ctx.globalCompositeOperation = 'screen';

  for(let y=0; y<GH; y++) {
      for(let x=0; x<GW; x++) {
          const idx = gi(x,y);
          const fx = x * CS;
          const fy = y * CS;
          
          let r=0, g=0, b=0, a=0;
          let trailFound = false;

          CFG.categories.forEach(cat => {
              const val = grid[cat.id][idx];
              if(val > 0) {
                  const factor = val / maxPh * 0.6;
                  if(cat.id === 'incident') r = Math.max(r, factor * 255); 
                  if(cat.id === 'request') g = Math.max(g, factor * 255); 
                  if(cat.id === 'problem') b = Math.max(b, factor * 255); 
                  a = Math.max(a, val / maxPh * 0.4);
                  trailFound = true;
              }
          });
          
          const foodVal = grid.food[idx];
          if (foodVal > 0) {
              const factor = foodVal / maxPh * 0.4;
              r = Math.max(r, factor * 100); 
              g = Math.max(g, factor * 200); 
              b = Math.max(b, factor * 255); 
              a = Math.max(a, foodVal / maxPh * 0.3);
              trailFound = true;
          }

          if(trailFound) {
              ctx.fillStyle = `rgba(${Math.min(255, r)}, ${Math.min(255, g)}, ${Math.min(255, b)}, ${a})`;
              ctx.fillRect(fx, fy, CS, CS);
          }
      }
  }

  ctx.globalCompositeOperation = 'source-over';
}


function updateFPS(now) {
    // ... (updateFPS remains the same) ...
    if (lastFrameTime) {
        fps = 1000 / (now - lastFrameTime);
        fpsDisplay.innerText = `FPS: ${fps.toFixed(0)}`;
    }
    lastFrameTime = now;
}

function updateAdaptiveLearning() {
    const total = stats.solved + stats.wrong;
    const successRate = total ? stats.solved / total : 0;
    adaptive.successEMA = adaptive.successEMA * 0.96 + successRate * 0.04;

    const stalledRatio = agents.length ? agents.filter(a => a.stalled).length / agents.length : 0;
    adaptive.stallEMA = adaptive.stallEMA * 0.9 + stalledRatio * 0.1;

    const avgReward = agents.length
        ? agents.reduce((sum, a) => sum + (a.accumulatedReward || 0), 0) / agents.length
        : 0;
    adaptive.rewardEMA = adaptive.rewardEMA * 0.9 + avgReward * 0.1;
    const rewardDelta = avgReward - adaptive.rewardEMA;
    adaptive.rewardVar = adaptive.rewardVar * 0.9 + rewardDelta * rewardDelta * 0.1;

    let eps = CFG.RL_EPSILON * (1.1 - adaptive.successEMA * 0.6);
    eps += adaptive.stallEMA * 0.08;
    adaptive.epsilon = clamp(eps, CFG.smart.epsilonMin, CFG.smart.epsilonMax);

    const volatility = Math.sqrt(adaptive.rewardVar);
    let alpha = CFG.RL_ALPHA * (1 + clamp(volatility, 0, 1.2));
    adaptive.alpha = clamp(alpha, CFG.smart.alphaMin, CFG.smart.alphaMax);

    let activeTickets = 0;
    tickets.forEach(t => { if (t.x > 0) activeTickets += 1; });
    const loadRatio = activeTickets / Math.max(1, tickets.length);
    let decay = PHEROMONE_DECAY + (1 - adaptive.successEMA) * 0.004 + (loadRatio - 0.5) * 0.003;
    adaptive.decay = clamp(decay, 0.980, 0.999);
}

function updateUI() {
  document.getElementById('hudGen').innerText = `EPISODE ${episode}`;
  document.getElementById('dispGen').innerText = episode;
  document.getElementById('dispSolved').innerText = stats.solved;
  document.getElementById('dispWrong').innerText = stats.wrong;
  
  let total = stats.solved + stats.wrong;
  let acc = total === 0 ? 0 : (stats.solved / total) * 100;
  document.getElementById('dispAcc').innerText = acc.toFixed(1) + '%';
  document.getElementById('dispAcc').style.color = acc > 80 ? varStyles.accentOk : (acc > 50 ? '#fff' : varStyles.accentBad);

  let stalledCount = agents.filter(a => a.stalled).length;
  stats.activeCount = agents.length - stalledCount;

  document.getElementById('dispActive').innerText = `${stats.activeCount}/${agents.length}`;
  if(bestAgent) {
      document.getElementById('dispFit').innerText = bestAgent.qScore.toFixed(2);
  }

  // Learning pulse bars
  const epsilonPct = Math.round(getEffectiveEpsilon() * 100);
  const alphaVal = getEffectiveAlpha();
  const gammaVal = CFG.RL_GAMMA;

  const setBar = (id, pct) => {
      const bar = document.getElementById(id);
      if(bar) bar.style.width = `${clamp(pct,0,100)}%`;
  };

  setBar('barEpsilon', epsilonPct);
  setBar('barAlpha', alphaVal * 8000);
  setBar('barGamma', gammaVal * 120);

  const valEpsilonPulse = document.getElementById('valEpsilonPulse');
  if(valEpsilonPulse) valEpsilonPulse.innerText = `${epsilonPct}%`;
  const valAlphaPulse = document.getElementById('valAlphaPulse');
  if(valAlphaPulse) valAlphaPulse.innerText = alphaVal.toFixed(3);
  const valGammaPulse = document.getElementById('valGammaPulse');
  if(valGammaPulse) valGammaPulse.innerText = gammaVal.toFixed(2);

  const progress = clamp(frame / CFG.episodeDuration, 0, 1);
  const progressFill = document.getElementById('episodeFill');
  if(progressFill) progressFill.style.width = `${(CFG.manualEpisode ? 100 : progress * 100).toFixed(1)}%`;

  // Toggle Policy Visualization visibility based on checkbox
  brainCanvas.style.display = document.getElementById('chkBrainViz').checked ? 'block' : 'none';
}

function drawBrain(agent) {
    // ... (drawBrain adapted for Policy Network) ...
    if(!document.getElementById('chkBrainViz').checked || !agent) return;
  
    const W_B = brainCanvas.width;
    const H_B = brainCanvas.height;
    brainCtx.clearRect(0, 0, W_B, H_B);
    
    const net = agent.policy;
    const nodeR = 4; 
    
    const layerX = [W_B*0.15, W_B*0.5, W_B*0.85];
    const getY = (idx, total) => (H_B / (total + 1)) * (idx + 1);
    
    // --- DRAW CONNECTIONS ---
    brainCtx.lineWidth = 0.5; 
    
    const getLineColor = (weight, inputVal) => {
        const activation = weight * inputVal;
        const alpha = clamp(Math.abs(activation) * 0.8, 0.1, 0.6);
        return activation > 0 ? `rgba(0,255,150,${alpha})` : `rgba(255,50,50,${alpha})`;
    }

    // Input to Hidden
    for(let i=0; i<CFG.inputs; i++) {
        for(let h=0; h<CFG.hiddens; h++) {
            try{
                const w = net.w1[i*CFG.hiddens + h];
                brainCtx.strokeStyle = getLineColor(w, agent.lastState[i] || 0);
                brainCtx.beginPath(); brainCtx.moveTo(layerX[0], getY(i, CFG.inputs)); brainCtx.lineTo(layerX[1], getY(h, CFG.hiddens)); brainCtx.stroke();
            } catch(e) {}
        }
    }
    
    // Hidden to Output
    for(let h=0; h<CFG.hiddens; h++) {
        for(let o=0; o<CFG.outputs; o++) {
            try{
                const w = net.w2[h*CFG.outputs + o];
                const hVal = agent.lastHiddens ? agent.lastHiddens[h] : 0;
                brainCtx.strokeStyle = getLineColor(w, hVal);
                brainCtx.beginPath(); brainCtx.moveTo(layerX[1], getY(h, CFG.hiddens)); brainCtx.lineTo(layerX[2], getY(o, CFG.outputs)); brainCtx.stroke();
            } catch(e) {}
        }
    }

    // --- DRAW NODES & LABELS ---
    brainCtx.globalAlpha = 1;
    brainCtx.font = '8px monospace'; 
    
    // Input Nodes (State)
    brainCtx.textAlign = 'right';
    const inputLabels = [
        'Ticket_X', 'Ticket_Y',
        'Inc_X', 'Inc_Y', 'Req_X', 'Req_Y', 'Prob_X', 'Prob_Y',
        'Carry_INC', 'Carry_REQ', 'Carry_PROB',
        'Energy', 'Speed',
        'Wall_Dist', 'Ticket_Dist'
    ];
    for(let i=0; i<CFG.inputs; i++) {
        const val = agent.lastState[i] || 0;
        const c = Math.round(clamp(val, 0, 1) * 255);
        let color = `rgb(${c}, ${c}, ${c})`;
        if (i < 4) { 
            const intensity = clamp(Math.abs(val) * 255, 0, 255);
            color = val > 0 ? `rgb(0, ${intensity}, 150)` : `rgb(${intensity}, 0, 50)`;
        }

        brainCtx.fillStyle = color;
        brainCtx.beginPath(); brainCtx.arc(layerX[0], getY(i, CFG.inputs), nodeR, 0, Math.PI*2); brainCtx.fill();
        brainCtx.fillStyle = '#94a3b8';
        brainCtx.fillText(inputLabels[i], layerX[0] - nodeR - 2, getY(i, CFG.inputs) + 2);
    }

    // Hidden Nodes
    for(let i=0; i<CFG.hiddens; i++) {
        const val = agent.lastHiddens ? agent.lastHiddens[i] : 0;
        let color = 'rgb(68, 68, 85)'; 
        if (Math.abs(val) > 0.01) {
            const intensity = clamp(Math.abs(val) * 255, 50, 255);
            color = val > 0 ? `rgb(0, ${intensity}, 150)` : `rgb(${intensity}, 0, 50)`;
        }
        brainCtx.fillStyle = color;
        brainCtx.beginPath(); brainCtx.arc(layerX[1], getY(i, CFG.hiddens), nodeR-1, 0, Math.PI*2); brainCtx.fill();
    }
    
    // Output Nodes (Action Policy)
    brainCtx.textAlign = 'left';
    const outputLabels = ['STEER_BIAS', 'SPEED_FACT', 'BRAKE_FACT', 'GOAL_INC_WT', 'GOAL_REQ_WT', 'GOAL_PROB_WT']; 
    for(let i=0; i<CFG.outputs; i++) {
        const val = agent.lastOutputs ? agent.lastOutputs[i] : 0;
        
        let color = '#fff';
        if (Math.abs(val) > 0.01) {
            const intensity = clamp(Math.abs(val) * 255, 50, 255);
            color = val > 0 ? `rgb(0, ${intensity}, 150)` : `rgb(${intensity}, 0, 50)`;
        }

        brainCtx.fillStyle = color;
        brainCtx.beginPath(); brainCtx.arc(layerX[2], getY(i, CFG.outputs), nodeR, 0, Math.PI*2); brainCtx.fill();
        
        brainCtx.fillStyle = '#94a3b8';
        brainCtx.fillText(outputLabels[i], layerX[2] + nodeR + 2, getY(i, CFG.outputs) + 2);
    }
}

function drawFitnessGraph() {
    // ... (drawFitnessGraph adapted to track best Q-Score) ...
  const W_G = 360, H_G = 70;
  const fitCtx = document.getElementById('fitnessGraph').getContext('2d');
  
  const canvasElement = document.getElementById('fitnessGraph');
  canvasElement.width = W_G;
  canvasElement.height = H_G;

  if(history.length < 2) { fitCtx.clearRect(0,0,W_G,H_G); return; }
  
  fitCtx.clearRect(0,0,W_G,H_G);
  const maxFit = Math.max(...history.map(h=>h.best), 1); 
  const stepX = W_G / (history.length - 1);
  
  fitCtx.strokeStyle = varStyles.accentOk;
  fitCtx.lineWidth = 2;
  fitCtx.beginPath();
  
  history.forEach((h, i) => {
    // Clamp to 1.0 to avoid graph jumping too high initially
    const y = H_G - (h.best / maxFit * H_G * 0.9 + 5); 
    if(i===0) fitCtx.moveTo(0, y); else fitCtx.lineTo(i*stepX, y);
  });
  fitCtx.stroke();
}


function pushFeed(msg, type='normal') {
    // ... (pushFeed remains the same) ...
  const el = document.getElementById('feed');
  const div = document.createElement('div');
  div.className = `feed-item ${type}`;
  div.innerText = msg;
  el.prepend(div);
  if(el.children.length > 6) el.lastChild.remove();
}

function updateHoverTip(e) {
    // ... (updateHoverTip adapted for Q-Score) ...
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    let hoveredAgent = null;
    for(let a of agents) {
        if(dist(a.x, a.y, x, y) < a.r * 2) {
            hoveredAgent = a;
            break;
        }
    }
    
    if (hoveredAgent) {
        hoverTip.style.opacity = 1;
        hoverTip.style.left = `${e.clientX}px`;
        hoverTip.style.top = `${e.clientY}px`;
        hoverTip.innerHTML = `
            <strong>Status:</strong><br>
            Episode Fitness: <span style="color:var(--accent-ok)">${hoveredAgent.fitness.toFixed(2)}</span><br>
            Q-Score: <span style="color:${hoveredAgent.qScore > 0 ? '#0ff' : '#aaa'}">${hoveredAgent.qScore.toFixed(2)}</span><br>
            Energy: <span style="color:${hoveredAgent.energy > 0.3 ? '#0f0' : '#ff9900'}">${(hoveredAgent.energy * 100).toFixed(0)}%</span><br>
            Speed: ${hoveredAgent.vel.toFixed(1)} / ${CFG.maxSpeed}<br>
            Carrying: ${hoveredAgent.carrying ? hoveredAgent.carrying.def.label : 'None'}
        `;
    } else {
        hoverTip.style.opacity = 0;
    }
}


// --- MAIN LOOP ---
function init(resetPolicyWeights = true) {
  W = canvas.width = canvas.parentElement.offsetWidth;
  H = canvas.height = canvas.parentElement.offsetHeight;
  
  brainCanvas.width = 300;
  brainCanvas.height = 150;
  
  const goalLineY = H * 0.22;
  const nestY = H * 0.62;
  if (!nest) { 
      nest = new Nest(W / 2, nestY);
  } else {
       nest.x = W / 2; nest.y = nestY;
  }
  
  // Initialize Goal Zones
  goalZones = [
      { x: W*0.2, y: goalLineY, r: 40, id: 'incident', color: CFG.categories.find(c=>c.id==='incident').color, label: 'INCIDENT' },
      { x: W*0.5, y: goalLineY, r: 40, id: 'request', color: CFG.categories.find(c=>c.id==='request').color, label: 'SERVICE' },
      { x: W*0.8, y: goalLineY, r: 40, id: 'problem', color: CFG.categories.find(c=>c.id==='problem').color, label: 'PROBLEM' }
  ];
  
  // Set CFG from Sliders
  CFG.popSize = parseInt(document.getElementById('slPop').value); 
  CFG.ticketCount = parseInt(document.getElementById('slTicketCount').value); 
  CFG.ticketSpawn.layout = document.getElementById('slTicketLayout').value;
  CFG.ticketSpawn.grouping = document.getElementById('slTicketGrouping').value;
  CFG.episodeDuration = parseInt(document.getElementById('slDuration').value); 
  CFG.manualEpisode = document.getElementById('chkManualEpisode').checked;
  CFG.RL_ALPHA = parseInt(document.getElementById('slAlpha').value) / 1000;
  CFG.RL_GAMMA = parseInt(document.getElementById('slGamma').value) / 100;
  CFG.RL_EPSILON = parseInt(document.getElementById('slEpsilon').value) / 100;

  // Check for Topology Change (Hidden Nodes)
  const newHiddens = parseInt(document.getElementById('slHidden').value);
  const topologyChanged = newHiddens !== CFG.hiddens;
  if (topologyChanged) {
      CFG.hiddens = newHiddens;
      pushFeed(`Topology updated. Rebuilding Policy Networks...`, 'warn');
      resetPolicyWeights = true; // Force weight reset on topology change
  }

  PHEROMONE_DECAY = parseInt(document.getElementById('slDecay').value) / 1000;

  adaptive.epsilon = CFG.RL_EPSILON;
  adaptive.alpha = CFG.RL_ALPHA;
  adaptive.decay = PHEROMONE_DECAY;
  
  makeGrid(); 

  // Agent Initialization Logic
  if(agents.length !== CFG.popSize || topologyChanged) {
      // Re-create agents if population size or topology changed
      agents = [];
      for(let i=0; i<CFG.popSize; i++) agents.push(new Agent());
      bestAgent = agents[0];
  } else if (resetPolicyWeights) {
      // Reset weights of existing agents
      agents = agents.map(a => new Agent());
      bestAgent = agents[0];
  } else {
      // Keep weights, just reset episode state
      resetEpisode({ evolve: false });
  }

  if(resetPolicyWeights) {
      episode = 1; 
      history = []; 
  }
  
  tickets = [];
  for(let i=0; i<CFG.ticketCount; i++) tickets.push(new Ticket());
  
  if(!requestAnimationFrame.isLooping) {
      requestAnimationFrame.isLooping = true;
      requestAnimationFrame(loop);
  }
}

function resetEpisode({ evolve = true } = {}) {
  const ranked = [...agents].sort((a, b) => b.fitness - a.fitness);
  const eliteCount = Math.max(1, Math.floor(CFG.evolve.elite * ranked.length));
  const elites = ranked.slice(0, eliteCount);
  const eliteSet = new Set(elites);
  const pickElite = () => elites[Math.floor(Math.random() * elites.length)];
  const bestFitness = ranked[0] ? ranked[0].fitness : 0;

  agents.forEach(a => {
      // Reset agent state
      a.x = nest.x;
      a.y = nest.y;
      a.angle = rand(0, Math.PI*2);
      a.vel = 0;
      a.carrying = null;
      a.energy = 1.0;
      a.fitness = 0;
      a.stalled = false;
      a.trail = [];
      a.stuckFrames = 0;
      a.searchFrames = 0;
      a.progressStreak = 0;
      a.visitedCells = new Set();

      if (evolve && CFG.learningMode === 'evolve') {
          if (!eliteSet.has(a)) {
              if (Math.random() < CFG.evolve.fresh) {
                  a.policy = new PolicyNetwork(CFG.inputs, CFG.hiddens, CFG.outputs);
              } else {
                  const parent = pickElite();
                  a.policy = parent.policy.clone();
                  a.policy.mutate(CFG.evolve.mutRate, CFG.evolve.mutStrength);
              }
          }
      }
      a.qScore = 0;
  });

  // Track performance
  if(bestFitness > 0) {
      history.push({
          episode: episode,
          best: bestFitness
      });
  }

  bestAgent = elites[0] || agents[0];

  episode++;
  frame = 0;
  stats.solved = 0;
  stats.wrong = 0;
  
  makeGrid();
  tickets.forEach(t => t.respawn());
  pushFeed(`--- NEW EPISODE (${episode}) ---`);
}

function getTicketSpawnAreas() {
    const margin = 60;
    const top = 140;
    const bottom = H - 80;
    const left = margin;
    const right = W - margin;

    if (CFG.ticketSpawn.layout === 'lanes') {
        const laneWidth = (right - left) / 3;
        return [
            { xMin: left, xMax: left + laneWidth, yMin: top, yMax: bottom },
            { xMin: left + laneWidth, xMax: left + laneWidth * 2, yMin: top, yMax: bottom },
            { xMin: left + laneWidth * 2, xMax: right, yMin: top, yMax: bottom }
        ];
    }

    if (CFG.ticketSpawn.layout === 'corners') {
        const clusterW = (right - left) * 0.32;
        const clusterH = (bottom - top) * 0.28;
        return [
            { xMin: left, xMax: left + clusterW, yMin: top, yMax: top + clusterH },
            { xMin: right - clusterW, xMax: right, yMin: top, yMax: top + clusterH },
            { xMin: left, xMax: left + clusterW, yMin: bottom - clusterH, yMax: bottom },
            { xMin: right - clusterW, xMax: right, yMin: bottom - clusterH, yMax: bottom }
        ];
    }

    return [{ xMin: left, xMax: right, yMin: top, yMax: bottom }];
}

function getTicketSpawnPoint(typeIdx) {
    const areas = getTicketSpawnAreas();
    let areaIndex = Math.floor(Math.random() * areas.length);

    if (CFG.ticketSpawn.grouping === 'grouped') {
        areaIndex = typeIdx % areas.length;
    }

    const area = areas[areaIndex];
    return {
        x: rand(area.xMin, area.xMax),
        y: rand(area.yMin, area.yMax)
    };
}

function loop(now) {
  updateFPS(now);

  if(!paused) {
    // 1. Global Pheromone Update
    updateAdaptiveLearning();
    evaporate();
    
    for(let n=0; n<speedMult; n++) {
      frame++;
      
      if(!CFG.manualEpisode && frame > CFG.episodeDuration) { resetEpisode(); break; }
      
      tickets.forEach(t => { t.update(); });
      
      let currentBest = bestAgent;
      let maxFitness = bestAgent ? bestAgent.fitness : -Infinity;

      agents.forEach(a => {
        a.update();
        if(a.fitness > maxFitness) { maxFitness = a.fitness; currentBest = a; }
      });
      
      goalZones.forEach(z => {
        deposit(z.id, z.x, z.y, PHEROMONE_CAP * CFG.smart.zoneDeposit, { spread: PHEROMONE_SPREAD });
      });

      agents.forEach(a => {
        const leadType = a.carrying ? a.carrying.def.id : 'food';
        deposit(leadType, a.x, a.y, PHEROMONE_CAP * CFG.smart.agentDeposit, { spread: PHEROMONE_SPREAD });
      });

      // Update bestAgent continuously based on fitness
      bestAgent = currentBest;
      if (bestAgent) {
          const leadType = bestAgent.carrying ? bestAgent.carrying.def.id : 'food';
          deposit(leadType, bestAgent.x, bestAgent.y, PHEROMONE_CAP * CFG.smart.leaderDeposit, { spread: PHEROMONE_SPREAD });
      }
      updateParticles();
      
      // Drag logic
      if(mouse.dragAgent) {
        mouse.dragAgent.x = mouse.x; mouse.dragAgent.y = mouse.y; mouse.dragAgent.vel = 0;
      }
    }
    
    // --- DRAWING ---
    ctx.clearRect(0, 0, W, H);
    
    drawAgentTrail(); 
    drawPheromones(); 
    drawZones();
    nest.draw(); 
    tickets.forEach(t => { t.draw(); });
    agents.forEach(a => { a.draw(); });
    drawParticles();
  }
  
  drawBrain(bestAgent);
  drawFitnessGraph();
  updateUI();
  requestAnimationFrame(loop);
}

// --- EVENT LISTENERS ---
window.addEventListener('resize', () => { 
    W = canvas.width = canvas.parentElement.offsetWidth; 
    H = canvas.height = canvas.parentElement.offsetHeight; 
    if(nest) {
        nest.x = W / 2; nest.y = H * 0.62;
    } 
    init(false); 
});

canvas.addEventListener('mousedown', e => {
    // ... (Mouse listeners remain the same) ...
  const rect = canvas.getBoundingClientRect();
  mouse.x = e.clientX - rect.left; mouse.y = e.clientY - rect.top;
  mouse.down = true;
  
  if (dist(nest.x, nest.y, mouse.x, mouse.y) < nest.r) {
    mouse.dragNest = true;
  } else {
    const hitZone = goalZones.find(z => dist(z.x, z.y, mouse.x, mouse.y) < z.r);
    if(hitZone) {
      mouse.dragZone = hitZone; 
    } else {
      const hit = agents.find(a => dist(a.x, a.y, mouse.x, mouse.y) < 20);
      if(hit) mouse.dragAgent = hit;
    }
  }
});

canvas.addEventListener('mousemove', e => { 
    // ... (Mouse listeners remain the same) ...
  const rect = canvas.getBoundingClientRect(); 
  mouse.x = e.clientX - rect.left; mouse.y = e.clientY - rect.top; 
  
  if(mouse.dragNest) {
      nest.x = clamp(mouse.x, nest.r, W - nest.r);
      nest.y = clamp(mouse.y, nest.r, H - nest.r);
      makeGrid(); 
  } else if (mouse.dragZone) { 
      const r = mouse.dragZone.r;
      mouse.dragZone.x = clamp(mouse.x, r, W - r);
      mouse.dragZone.y = clamp(mouse.y, r, H - r);
  }
  updateHoverTip(e);
});

canvas.addEventListener('mouseup', () => { 
    // ... (Mouse listeners remain the same) ...
  mouse.down = false; 
  mouse.dragAgent = null; 
  mouse.dragNest = false; 
  mouse.dragZone = null; 
  hoverTip.style.opacity = 0; 
});

// Buttons & Keyboard
document.getElementById('btnSkip').onclick = () => { 
    if(paused) paused = false; 
    resetEpisode();
};

document.getElementById('btnResetAI').onclick = () => { 
    init(true); 
    pushFeed('Policy Weights Reset: Agents must learn from scratch.', 'bad'); 
};
document.getElementById('btnReset').onclick = () => { 
    init(true); 
    pushFeed('Hard Reset: All settings and AI reset', 'danger'); 
};

document.addEventListener('keydown', e => { 
    if(e.code === 'Space') { 
        paused = !paused; 
        pushFeed(paused ? 'Paused' : 'Unpaused', 'warn'); 
    }
    if(e.code === 'KeyS') document.getElementById('btnSkip').click(); 
});

// Sliders Logic
document.getElementById('slSpeed').oninput = (e) => { speedMult = parseInt(e.target.value); document.getElementById('valSpeed').innerText = speedMult + 'x'; };

document.getElementById('slPop').oninput = (e) => { 
    document.getElementById('valPop').innerText = e.target.value; 
    CFG.popSize = parseInt(e.target.value);
    init(false); 
};

document.getElementById('slTicketCount').oninput = (e) => { 
    CFG.ticketCount = parseInt(e.target.value); 
    document.getElementById('valTickets').innerText = CFG.ticketCount; 
    tickets = [];
    for(let i=0; i<CFG.ticketCount; i++) tickets.push(new Ticket());
};

document.getElementById('slTicketLayout').onchange = (e) => {
    CFG.ticketSpawn.layout = e.target.value;
    tickets.forEach(t => t.respawn());
};

document.getElementById('slTicketGrouping').onchange = (e) => {
    CFG.ticketSpawn.grouping = e.target.value;
    tickets.forEach(t => t.respawn());
};

document.getElementById('slDuration').oninput = (e) => { 
    CFG.episodeDuration = parseInt(e.target.value); 
    document.getElementById('valDuration').innerText = CFG.episodeDuration; 
};

document.getElementById('chkManualEpisode').onchange = (e) => {
    CFG.manualEpisode = e.target.checked;
};

document.getElementById('slSensor').oninput = (e) => { 
    CFG.sensorRange = parseInt(e.target.value); 
    document.getElementById('valSensor').innerText = CFG.sensorRange + 'px'; 
};

document.getElementById('slDrain').oninput = (e) => { 
    let val = parseInt(e.target.value);
    CFG.energyDrain = val * 0.0001; 
    let label = val < 5 ? 'Low' : (val > 15 ? 'Extreme' : 'Normal');
    document.getElementById('valDrain').innerText = label; 
};

document.getElementById('slDecay').oninput = (e) => { 
    let val = parseInt(e.target.value);
    PHEROMONE_DECAY = val / 1000; 
    adaptive.decay = PHEROMONE_DECAY;
    document.getElementById('valDecay').innerText = PHEROMONE_DECAY.toFixed(3); 
};

// RL Sliders
document.getElementById('slAlpha').oninput = (e) => { 
    let val = parseInt(e.target.value);
    CFG.RL_ALPHA = val / 1000;
    adaptive.alpha = CFG.RL_ALPHA;
    document.getElementById('valAlpha').innerText = CFG.RL_ALPHA.toFixed(3); 
};

document.getElementById('slGamma').oninput = (e) => { 
    let val = parseInt(e.target.value);
    CFG.RL_GAMMA = val / 100;
    document.getElementById('valGamma').innerText = CFG.RL_GAMMA.toFixed(2); 
};

document.getElementById('slEpsilon').oninput = (e) => { 
    let val = parseInt(e.target.value);
    CFG.RL_EPSILON = val / 100;
    adaptive.epsilon = CFG.RL_EPSILON;
    document.getElementById('valEpsilon').innerText = val + '%'; 
};

document.getElementById('slHidden').oninput = (e) => { 
    document.getElementById('valHidden').innerText = e.target.value; 
    pushFeed('Hidden Nodes changed. Press "Hard Reset All" to refresh the Policy Networks.', 'warn');
};


init();
</script>
</body>
</html>
